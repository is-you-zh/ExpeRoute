import json
from tqdm import tqdm
import os
from prompt import FILTER_DATASET_PROMPT
from models import gpt_for_data
TO_CLEAN_FILE = 'tool_data_new.json' 
# ä»¥ä¸‹å‡½æ•°éƒ½å¯ç”¨ï¼Œåªéœ€ä¿®æ”¹æ–‡ä»¶åç§°ï¼Œå°†è¾“å…¥å’Œè¾“å‡ºæ”¹æˆä¸Šä¸€çº§å¤„ç†å¥½çš„æ–‡ä»¶åå³å¯

def get_all_tools_list_from_query():
    """
    ä»æŸ¥è¯¢æ•°æ®é›†ä¸­è·å¾—æ‰€æœ‰å·¥å…·åˆ—è¡¨
    """
    with open('/root/autodl-tmp/AnyTool/data/instruction/G1_query.json', 'r', encoding='utf-8') as f:
        data = json.load(f)

    new_data = {}

    for item in data:
        for api in item['api_list']:
            category = api['category_name']
            tool = api['tool_name']
            api_name = api['api_name']

            if category not in new_data:
                new_data[category] = {}

            if tool not in new_data[category]:
                new_data[category][tool] = {'api_list_names': []}

            if api_name not in new_data[category][tool]['api_list_names']:
                new_data[category][tool]['api_list_names'].append(api_name)

    with open('tool_data_new.json', 'w', encoding='utf-8') as f:
        json.dump(new_data, f, ensure_ascii=False, indent=4)

    print("âœ… æ–°æ–‡ä»¶å·²ä¿å­˜ä¸º tool_data_new.json")

def get_all_tools_list_from_query_update():
    """
    æ›´æ–°åˆšç”Ÿæˆçš„å·¥å…·åˆ—è¡¨
    """
    with open('tool_data_new.json', 'r', encoding='utf-8') as f:
        existing_data = json.load(f)

    # åŠ è½½æ–°çš„ input æ–‡ä»¶
    # with open('/root/autodl-tmp/AnyTool/data/test_instruction/G2_category.json', 'r', encoding='utf-8') as f:
    with open('/root/autodl-tmp/AnyTool/data/instruction/G3_query.json', 'r', encoding='utf-8') as f:
        new_data = json.load(f)

    for item in new_data:
        for api in item['api_list']:
            category = api['category_name']
            tool = api['tool_name']
            api_name = api['api_name']

            if category not in existing_data:
                existing_data[category] = {}

            if tool not in existing_data[category]:
                existing_data[category][tool] = {'api_list_names': []}

            if api_name not in existing_data[category][tool]['api_list_names']:
                existing_data[category][tool]['api_list_names'].append(api_name)

    with open('tool_data_new.json', 'w', encoding='utf-8') as f:
        json.dump(existing_data, f, ensure_ascii=False, indent=4)

    print("âœ… æ–° API å·²è¿½åŠ åˆ° tool_data_new.json")

def get_complete_tools_list():
    """
    å°†æå–çš„å·¥å…·çš„apiåˆ—è¡¨æ›¿æ¢ä¸ºå®Œå…¨çš„apiåˆ—è¡¨(å¯é€‰)
    ä¸€ä¸ªæ–‡ä»¶æ˜¯ä»æ•°æ®é›†ä¸­æå–çš„ï¼Œå¦ä¸€ä¸ªæ˜¯å®Œæ•´çš„å·¥å…·åˆ—è¡¨
    """
    with open('tool_data_new.json', 'r', encoding='utf-8') as f:
        output_data = json.load(f)

    with open('tool_data.json', 'r', encoding='utf-8') as f:
        tool_data = json.load(f)

    for category in output_data:
        if category in tool_data:
            for tool in output_data[category]:
                if tool in tool_data[category]:
                    # ç”¨ tool_data ä¸­çš„ api_list_names è¦†ç›–æ‰ output
                    output_data[category][tool]['api_list_names'] = tool_data[category][tool]['api_list_names']
                    print(f"âœ… æ›¿æ¢äº† {category} â†’ {tool} çš„ api_list_names")

    with open('tool_data_updated.json', 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=4)

    print("ğŸ‰ å·²ç”Ÿæˆ tool_data_updated.jsonï¼Œæ›¿æ¢å®Œæˆï¼")

def count_query_number():
    """
    è®¡ç®—ä¸‰ä¸ªqueryæ–‡ä»¶ä¸­å…±æœ‰å¤šå°‘ä¸ªå…ƒç´ ï¼Œå³å¤šå°‘ä¸ªæŸ¥è¯¢
    """
    # åŠ è½½ input.json
    with open('/root/autodl-tmp/AnyTool/data/instruction/G1_query.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
    with open('/root/autodl-tmp/AnyTool/data/instruction/G2_query.json', 'r', encoding='utf-8') as f:
        data2 = json.load(f)
    with open('/root/autodl-tmp/AnyTool/data/instruction/G3_query.json', 'r', encoding='utf-8') as f:
        data3 = json.load(f)
    # ç»Ÿè®¡å…ƒç´ æ•°
    count1 = len(data)
    count2 = len(data2)
    count3 = len(data3)
    # âœ… input.json ä¸­å…±æœ‰ 201774 ä¸ªå…ƒç´ 
    print(f"âœ… input.json ä¸­å…±æœ‰ {count1+count2+count3} ä¸ªå…ƒç´ ")

def remove_specified_keys(json_file_path, keys_to_remove, output_file_path=None):
    """
    åˆ é™¤ä¸è¦çš„ç±»ã€‚
    ä» JSON æ–‡ä»¶ä¸­åˆ é™¤æŒ‡å®šçš„ key å¹¶ä¿å­˜ã€‚
    :param json_file_path: è¾“å…¥çš„ JSON æ–‡ä»¶è·¯å¾„
    :param keys_to_remove: è¦åˆ é™¤çš„ key åˆ—è¡¨
    :param output_file_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœä¸º Noneï¼Œåˆ™è¦†ç›–åŸæ–‡ä»¶ï¼‰
    """

    # å…±æœ‰50ä¸ªç§ç±»ï¼Œå…¶ä¸­æœ‰ä¸€ä¸ªæ˜¯Customizedï¼Œè‡ªå»ºç±»åˆ«ï¼Œé™¤æ­¤å¤–åˆ é™¤7ä¸ªï¼Œè¿˜å‰©42ä¸ªç±»åˆ«çš„å·¥å…·
    keys_to_remove = ["Monitoring", "Storage", "Devices", "Cybersecurity", "Payments", "Cryptography", "Reward"]
    with open(json_file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    for key in keys_to_remove:
        if key in data:
            del data[key]
            print(f"Removed key: {key}")
        else:
            print(f"Key not found, skipped: {key}")
    
    output_path = output_file_path if output_file_path else json_file_path
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)
    
    print(f"Finished saving updated JSON to {output_path}")

def get_all_tools_list():
    """
    å°†æ‰€æœ‰å·¥å…·åˆ—å‡ºæ¥æ”¾åˆ°ä¸€ä¸ªtxtæ–‡ä»¶ä¸­
    """
    with open('tool_data_new_cleaned_api.json', 'r', encoding='utf-8') as f:
        data = json.load(f)

    with open('all_tools_list_hhh_last.txt', 'w', encoding='utf-8') as out:
        for category, tools in data.items():
            out.write(f"\n=== Category: {category} ===\n")
            for tool_name in tools.keys():
                out.write(f"- {tool_name}\n")

def get_all_tools_list_no():
    """
    å°†æ‰€æœ‰å·¥å…·åˆ—å‡ºæ¥æ”¾åˆ°ä¸€ä¸ªtxtæ–‡ä»¶ä¸­ï¼Œæ²¡æœ‰æ¢è¡Œ
    """
    with open('tool_data.json', 'r', encoding='utf-8') as f:
        data = json.load(f)

    with open('tool_list_cleaned.txt', 'w', encoding='utf-8') as out:
        for category, tools in data.items():
            tool_names = [f'"{tool}"' for tool in tools.keys()]
            joined_tools = ', '.join(tool_names)
            out.write(f"=== Category: {category} ===\n")
            out.write(f"{joined_tools}\n\n")

def clean_category_tools(input_json_path, category, tools_to_remove):
    """
    ä»æŒ‡å®šç±»åˆ«ä¸­åˆ é™¤å·¥å…·ï¼Œå¹¶è¦†ç›–ä¿å­˜åŸæ–‡ä»¶ã€‚

    å‚æ•°ï¼š
    - input_json_path: è¾“å…¥ JSON æ–‡ä»¶è·¯å¾„ï¼ˆè¦†ç›–ä¿å­˜ï¼‰
    - category: è¦å¤„ç†çš„ç±»åˆ«åï¼ˆåŒºåˆ†å¤§å°å†™ï¼Œå¦‚ 'Email'ï¼‰
    - tools_to_remove: è¦åˆ é™¤çš„å·¥å…·åé›†åˆï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
    """
    with open(input_json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    if category in data:
        category_tools = data[category]
        filtered_tools = {
            tool_name: info for tool_name, info in category_tools.items()
            if tool_name.lower() not in tools_to_remove
        }
        data[category] = filtered_tools
        print(f"âœ… {len(category_tools) - len(filtered_tools)} tools have been removed from the category '{category}'.")
    else:
        print(f"âš  The category '{category}' does not exist, skipping processing.")

    with open(input_json_path, 'w', encoding='utf-8') as f_out:
        json.dump(data, f_out, ensure_ascii=False, indent=2)

def merge_info():
    """
    å°†api_details.jsonå’Œcategory_tool_details.jsonè¿›è¡Œåˆå¹¶
    ç¬¬ä¸€ä¸ªæ–‡ä»¶æœ‰apiçš„æè¿°ï¼Œç¬¬äºŒä¸ªæ–‡ä»¶æœ‰å·¥å…·æè¿°
    """
    with open('api_details.json', 'r', encoding='utf-8') as f:
        api_details = json.load(f)

    with open('category_tool_details.json', 'r', encoding='utf-8') as f:
        tool_details = json.load(f)

    # åˆå¹¶å·¥å…·æè¿°
    merged_details = {}
    for category, tools in api_details.items():
        merged_details[category] = {}
        for tool_name, tool_info in tools.items():
            merged_details[category][tool_name] = {
                'description': tool_details.get(category, {}).get(tool_name, {}).get('tool_description', ''),
                'api_list': tool_info.get('api_list', [])
            }

    with open('merged_details.json', 'w', encoding='utf-8') as f:
        json.dump(merged_details, f, indent=4, ensure_ascii=False)

    print("åˆå¹¶å®Œæˆï¼Œç»“æœå·²ä¿å­˜ä¸º merged_details.json")

def clean_null_tool():
    """
    ä»å·²ç»åˆå¹¶å¥½çš„jsonæ–‡ä»¶ä¸­ï¼Œæ¸…ç†æ— æè¿°çš„å·¥å…·
    """
    with open('merged_details.json', 'r', encoding='utf-8') as f:
        data = json.load(f)

    deleted_tools = {}
    total_deleted_count = 0

    for category, tools in data.items():
        cleaned_tools = {}
        deleted_in_category = []

        for tool_name, tool_info in tools.items():
            print(tool_name)
            desc_raw = tool_info.get('description')
            description = desc_raw if isinstance(desc_raw, str) else ''
            description = description.strip()

            if description != '':
                cleaned_tools[tool_name] = tool_info
            else:
                deleted_in_category.append(tool_name)
                total_deleted_count += 1  

        data[category] = cleaned_tools
        if deleted_in_category:
            deleted_tools[category] = deleted_in_category

    with open('merged_output_cleaned.json', 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

    print("âœ… æ¸…ç†å®Œæˆï¼")
    print(f"ä¿ç•™çš„å·¥å…·å·²ä¿å­˜åˆ°ï¼šoutput_cleaned.json")
    print(f"è¢«åˆ é™¤çš„å·¥å…·åå­—å·²ä¿å­˜åˆ°ï¼šoutput_deleted.json")
    print(f"æ€»å…±åˆ é™¤äº† {total_deleted_count} ä¸ªå·¥å…·ã€‚")

def remove_deleted_tools_from_second_file():
    """
    ä»ç¬¬äºŒä¸ªæ–‡ä»¶(tool_data_new.json)ä¸­ä¹Ÿåˆ é™¤åˆšæ‰å› ä¸ºæ²¡æœ‰å·¥å…·æè¿°è€Œè¢«åˆ é™¤çš„å·¥å…·
    tool_data_new.jsonä¿å­˜çš„æ˜¯å·¥å…·åˆ—è¡¨åŠapiåç§°ï¼Œç®€ç•¥ä¿¡æ¯
    merged_output_cleaned.jsonä¿å­˜çš„æ˜¯å·¥å…·æè¿°åŠapiæ–‡æ¡£çš„è¯¦ç»†ä¿¡æ¯
    æœ‰æ—¶ä¸ºäº†ä¸åŠ è½½å¤§æ–‡ä»¶ï¼Œæ‰€ä»¥éœ€è¦ä»ç¬¬äºŒä¸ªæ–‡ä»¶å¯¹åº”çš„åˆ é™¤è¢«åˆ é™¤çš„å·¥å…·
    """
    with open('merged_output_deleted.json', 'r', encoding='utf-8') as f:
        deleted_tools = json.load(f)

    with open('tool_data_new.json', 'r', encoding='utf-8') as f:
        second_data = json.load(f)

    total_removed = 0
    removed_count_by_category = {}

    for category, tools in deleted_tools.items():
        if category in second_data:
            removed_count_by_category[category] = 0 

            for tool in tools:
                if tool in second_data[category]:
                    del second_data[category][tool]
                    total_removed += 1
                    removed_count_by_category[category] += 1

    with open('tool_data_new_cleaned.json', 'w', encoding='utf-8') as f:
        json.dump(second_data, f, ensure_ascii=False, indent=4)

    print(f"âœ… åˆ é™¤å®Œæˆï¼Œæ€»å…±åˆ é™¤äº† {total_removed} ä¸ªå·¥å…·ã€‚")
    for category, count in removed_count_by_category.items():
        print(f"  - {category}: åˆ é™¤äº† {count} ä¸ªå·¥å…·ã€‚")

    print("æ–°æ–‡ä»¶ä¿å­˜ä¸ºï¼šsecond_file_cleaned.json")

def remove_null_api():
    """
    ä»å…¨éƒ¨çš„merged_output_cleaned.jsonä¸­åˆ é™¤descriptionä¸ºç©ºçš„apiï¼Œå¦‚æœåˆ å®Œapiä¹‹åtoolæ²¡æœ‰apiäº†ï¼Œä¹Ÿåˆ é™¤tool
    å¹¶ä¿å­˜åˆ æ‰äº†å“ªäº›toolå’Œapi
    """

    with open('merged_output_cleaned.json', 'r', encoding='utf-8') as f:
        data = json.load(f)

    deleted_api_count = 0
    deleted_tool_count = 0

    deleted_apis = {}  
    deleted_tools = {}   

    for category, tools in list(data.items()):
        tools_to_delete = []

        for tool_name, tool_info in list(tools.items()):
            api_list = tool_info.get('api_list', [])
            kept_apis = []
            removed_api_names = []

            for api in api_list:
                desc = api.get('description')
                print(desc)
                if desc is None or str(desc).strip() == '':
                    removed_api_names.append(api.get('name', 'unknown'))
                    deleted_api_count += 1
                else:
                    kept_apis.append(api)

            if removed_api_names:
                if category not in deleted_apis:
                    deleted_apis[category] = {}
                deleted_apis[category][tool_name] = removed_api_names

            if kept_apis:
                tool_info['api_list'] = kept_apis
            else:
                tools_to_delete.append(tool_name)

        for tool_name in tools_to_delete:
            del tools[tool_name]
            deleted_tool_count += 1
            if category not in deleted_tools:
                deleted_tools[category] = []
            deleted_tools[category].append(tool_name)

    print(f"âœ… æ€»å…±åˆ é™¤äº† {deleted_api_count} ä¸ª API")
    print(f"âœ… æ€»å…±åˆ é™¤äº† {deleted_tool_count} ä¸ªå·¥å…·")

    with open('merged_output_cleaned_api.json', 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    with open('deleted_apis.json', 'w', encoding='utf-8') as f:
        json.dump(deleted_apis, f, ensure_ascii=False, indent=2)

    with open('deleted_tools.json', 'w', encoding='utf-8') as f:
        json.dump(deleted_tools, f, ensure_ascii=False, indent=2)

def clean_null_apis_from_second_file():
    """
    ä»tool_data_new_cleaned.jsonä¸­åˆ é™¤descriptionä¸ºç©ºçš„apiå¹¶ç”Ÿæˆæ–°æ–‡ä»¶
    """
    with open('tool_data_new_cleaned.json', 'r') as f:
        data = json.load(f)

    with open('deleted_tools.json', 'r') as f:
        delete_tool = json.load(f)

    with open('deleted_apis.json', 'r') as f:
        delete_api = json.load(f)

    deleted_api_count = 0
    deleted_tool_count = 0

    for category, tools in list(data.items()):
        for tool_name, tool_info in list(tools.items()):
            apis_to_delete = delete_api.get(category, {}).get(tool_name, [])
            if apis_to_delete:
                original_len = len(tool_info['api_list_names'])
                tool_info['api_list_names'] = [api for api in tool_info['api_list_names'] if api not in apis_to_delete]
                deleted_count = original_len - len(tool_info['api_list_names'])
                deleted_api_count += deleted_count

            if not tool_info['api_list_names']:
                del data[category][tool_name]
                deleted_tool_count += 1

    for category, tools_to_remove in delete_tool.items():
        for tool_name in tools_to_remove:
            if tool_name in data.get(category, {}):
                del data[category][tool_name]
                deleted_tool_count += 1

    for category in list(data.keys()):
        if not data[category]:
            del data[category]

    print(f"âœ… åˆ é™¤çš„ API æ€»æ•°: {deleted_api_count}")
    print(f"âœ… åˆ é™¤çš„å·¥å…·æ€»æ•°: {deleted_tool_count}")

    with open('tool_data_new_cleaned_api.json', 'w') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

def count_api_number():
    """
    ç»Ÿè®¡æ¯ä¸ªç±»ä¸­çš„å·¥å…·å’ŒAPIæ•°é‡
    """
    with open('./data/tool_data.json', 'r', encoding='utf-8') as f:
        data = json.load(f)

    total_classes = len(data)
    total_tools = 0
    total_apis = 0

    class_stats = []
    for class_name, tools in data.items():
        num_tools = len(tools)
        num_apis = sum(len(tool_info.get('api_list_names', [])) for tool_info in tools.values())
        
        total_tools += num_tools
        total_apis += num_apis
        
        class_stats.append({
            'class_name': class_name,
            'num_tools': num_tools,
            'num_apis': num_apis
        })

    class_stats.sort(key=lambda x: x['num_tools'], reverse=True)

    print(f"æ€»å…±æœ‰ {total_classes} ä¸ªç±»\n")

    for stats in class_stats:
        print(f"ç±»: {stats['class_name']}")
        print(f"  å·¥å…·æ•°é‡: {stats['num_tools']}")
        print(f"  API æ€»æ•°: {stats['num_apis']}\n")

    print(f"ç»¼åˆç»Ÿè®¡ï¼š")
    print(f"  æ€»å·¥å…·æ•°é‡: {total_tools}")
    print(f"  æ€» API æ•°é‡: {total_apis}")

def count_apis_per_tool_from_file(file_path):
    """"
    æŸ¥çœ‹æ¯ä¸ªå·¥å…·æœ‰å¤šå°‘apiå¹¶ä¿å­˜åœ¨ä¸€ä¸ªjsonæ–‡ä»¶ä¸­
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    result = []

    for category, tools in data.items():
        for tool_name, tool_info in tools.items():
            api_list = tool_info.get("api_list_names", [])
            result.append({
                "category": category,
                "tool": tool_name,
                "api_count": len(api_list)
            })

    result.sort(key=lambda x: x["api_count"], reverse=True)

    with open('tool_api_count_sorted.json', 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

def filter_api_by_reference():
    """
    å‡å°‘æ–‡ä»¶çš„å¤§å°ï¼Œåˆ é™¤æ²¡ç”¨çš„ä¿¡æ¯ï¼ˆå·²ç»åˆ æ‰çš„apiæˆ–å·¥å…·ï¼‰
    è¯»å–ä¸¤ä¸ª JSON æ–‡ä»¶ï¼š
    - 'merged_output_cleaned_api.json' åŒ…å«å®Œæ•´çš„ç±»åˆ«ã€å·¥å…·å’Œ API ä¿¡æ¯ï¼›
    - 'tool_data_new_v2.json' åŒ…å«éœ€è¦ä¿ç•™çš„ç±»åˆ«ã€å·¥å…·åŠ API åç§°ã€‚

    å‡½æ•°å°†æ ¹æ®ç¬¬äºŒä¸ªæ–‡ä»¶ä¸­çš„ API åç§°ç­›é€‰ç¬¬ä¸€ä¸ªæ–‡ä»¶ä¸­çš„å†…å®¹ï¼Œ
    åªä¿ç•™å‡ºç°åœ¨ç¬¬äºŒä¸ªæ–‡ä»¶ä¸­çš„ APIï¼Œæœ€åå°†ç»“æœä¿å­˜ä¸º 'filtered_api_output.json'ã€‚

    è¿”å›ï¼š
        dictï¼Œç­›é€‰åçš„æ•°æ®ç»“æ„ã€‚
    """

    with open('/root/autodl-tmp/ToolCombine/ToolsTree0307/data/api_details.json', 'r', encoding='utf-8') as f1:
        full_data = json.load(f1)

    with open('/root/autodl-tmp/ToolCombine/ToolsTree0307/data/tool_data.json', 'r', encoding='utf-8') as f2:
        filter_data = json.load(f2)

    filtered_result = {}

    for category, tools in filter_data.items():
        if category not in full_data:
            continue
        for tool_name, tool_info in tools.items():
            if tool_name not in full_data[category]:
                continue

            allowed_api_names = set(tool_info.get("api_list_names", []))
            original_api_list = full_data[category][tool_name].get("api_list", [])
            new_api_list = [
                api for api in original_api_list
                if api["name"] in allowed_api_names
            ]

            if new_api_list:
                if category not in filtered_result:
                    filtered_result[category] = {}
                filtered_result[category][tool_name] = {
                    "description": full_data[category][tool_name].get("description", ""),
                    "api_list": new_api_list
                }

    # ä¿å­˜ä¸ºæ–°æ–‡ä»¶
    with open('api_details.json', 'w', encoding='utf-8') as f_out:
        json.dump(filtered_result, f_out, indent=2, ensure_ascii=False)

    print("The new file has been saved to filtered_api_output.json")

def clean_and_overwrite_tool_file():
    """
    å»é™¤api_details.jsonä¸­toolåŠapiçš„åç§°å‰åçš„ç©ºæ ¼
    """
    file_path = "api_details.json"
    with open(file_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    for category, tools in data.items():
        cleaned_tools = {}
        for tool_name, tool_info in tools.items():
            clean_tool_name = tool_name.strip()

            cleaned_apis = []
            for api in tool_info.get("api_list", []):
                api["name"] = api["name"].strip()
                cleaned_apis.append(api)

            tool_info["api_list"] = cleaned_apis
            cleaned_tools[clean_tool_name] = tool_info

        data[category] = cleaned_tools

    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def clean_api_list_names():
    """
    åŒä¸Š
    å»é™¤tool_dataä¸­å·¥å…·åŠapiåç§°å‰åçš„ç©ºæ ¼
    """
    file_path = "tool_data.json"
    with open(file_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    for category, tools in data.items():
        # è®°å½•éœ€è¦é‡å‘½åçš„å·¥å…·
        rename_map = {}

        for tool_name, tool_info in tools.items():
            clean_tool_name = tool_name.strip()

            # æ¸…æ´— API åç§°å‰åç©ºæ ¼
            if "api_list_names" in tool_info:
                cleaned_api_list = [api.strip() for api in tool_info["api_list_names"]]
                tool_info["api_list_names"] = cleaned_api_list

            # å¦‚æœå·¥å…·åéœ€è¦é‡å‘½åï¼Œæš‚å­˜
            if clean_tool_name != tool_name:
                rename_map[tool_name] = clean_tool_name

        # åœ¨å¾ªç¯å¤–æ‰§è¡Œé”®çš„é‡å‘½å
        for old_name, new_name in rename_map.items():
            tools[new_name] = tools.pop(old_name)

    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def count_json_elements(file_path):
    """
    ç»Ÿè®¡JSONæ–‡ä»¶çš„æ ¹ç»“æ„å…ƒç´ æ•°é‡
    å‚æ•°:
    file_path (str): JSONæ–‡ä»¶è·¯å¾„
    è¿”å›:
    str: åŒ…å«JSONç»“æ„ç±»å‹å’Œå…ƒç´ æ•°é‡çš„å­—ç¬¦ä¸²
    """
    try:
        # è¯»å–JSONæ–‡ä»¶
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æ ¹æ®ç»“æ„ç±»å‹ç»Ÿè®¡å…ƒç´ æ•°é‡
        if isinstance(data, dict):
            # å¯¹è±¡ç±»å‹ï¼šç»Ÿè®¡é”®å€¼å¯¹æ•°é‡
            element_count = len(data)
            structure_type = "å¯¹è±¡ï¼ˆé”®å€¼å¯¹ï¼‰"
        elif isinstance(data, list):
            # æ•°ç»„ç±»å‹ï¼šç»Ÿè®¡æ•°ç»„é¡¹æ•°
            element_count = len(data)
            structure_type = "æ•°ç»„"
        else:
            # å…¶ä»–ç±»å‹ï¼ˆå¦‚å•ä¸ªå€¼ï¼‰
            element_count = 1
            structure_type = "å•ä¸ªå€¼"
        
        print(f"JSONç»“æ„ç±»å‹ï¼š{structure_type}\nå…ƒç´ æ•°é‡ï¼š{element_count}")

    
    except FileNotFoundError:
        print("é”™è¯¯ï¼šæ–‡ä»¶ '{}' ä¸å­˜åœ¨".format(file_path))
    except json.JSONDecodeError:
        print("é”™è¯¯ï¼šæ–‡ä»¶ '{}' ä¸æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼".format(file_path))
    except Exception as e:
        print("é”™è¯¯ï¼šå‘ç”ŸæœªçŸ¥å¼‚å¸¸ - {}".format(str(e)))

def clean_bad_tools():
    """
    åˆ¶å®šä¸€äº›æ ‡å‡†ï¼Œä½¿ç”¨ChatGPTååŠ©åˆ é™¤ä¸€äº›æ— ç”¨çš„å·¥å…·ï¼Œå¹¶åˆ¶å®šæ ‡å‡†ï¼Œä»è¦åˆ é™¤åˆ—è¡¨ä¸­è¿›è¡Œè¯¯åˆ æ‰¾å›
    å…±æ•´ç†äº†37ä¸ªç±»åˆ«
    """
    target_category = "Data"
    # åˆ é™¤125ä¸ªå·¥å…·
    data_tools_to_remove = [
        "RaastaAPI",              # åå­—æ¨¡ç³Š
        "frrefe",                 # æ‹¼å†™ä¹±ï¼Œä¸çŸ¥å•¥
        "scout",                  # åå­—æ¨¡ç³Š
        "France 2D",              # å°ä¼—å¥‡æ€ªï¼Œä¸çŸ¥å•¥
        "Thai Lotto New API",     # åç¦»ï¼Œå½©ç¥¨ä¸“ç”¨ï¼Œéé€šç”¨æ•°æ®
        "Thai Lottery Result",    # åŒä¸Š
        "Holy Bible",             # åå†…å®¹
        "Complete Study Bible",   # åå†…å®¹
        "Motivational Content",   # åå†…å®¹
        "Todo Lsit",              # æ‹¼é”™ï¼Œå ä½
        "Reqres",                 # æµ‹è¯•ç”¨ API
        "10000+ Anime Quotes With Pagination Support",  # åå†…å®¹
        "Unicode Codepoints",     # åå·¥å…·ç±»
        "Dog breeds",             # åå†…å®¹
        "Fish species",           # åå†…å®¹
        "House Plants",           # åå†…å®¹
        "Matrimony Profiles",     # åå†…å®¹ï¼Œéé€šç”¨æ•°æ®
        "Kick.com API | Kick API",# å°ä¼—ï¼Œåå¹³å°å·¥å…·
        "Lotto Draw Results - Global", # å½©ç¥¨åç¦»
        "Trinidad Covid 19 Statistics",# å°ä¼—åœ°åŒºï¼Œæ—¶æ•ˆæ€§å¼±
        "Tesla VIN Identifier",   # åè½¦è¾†å·¥å…·ç±»
        "VRM STR Tools",          # æ‹¼å†™æ¨¡ç³Šï¼ŒæŸ¥ä¸åˆ°
        "Liquidation Report",     # æ‹¼å†™æ¨¡ç³Šï¼ŒæŸ¥ä¸åˆ°
        "Random Chunk API",       # æ¨¡ç³Šï¼Œä¸çŸ¥å•¥
        "StopModReposts Blocklist",# åå†…å®¹ï¼Œéé€šç”¨æ•°æ®
        "Pocket Cube Solver",                 # å°ä¼—ã€åå¨±ä¹
        "Flowers",                            # åå†…å®¹
        "Cat breeds",                         # åå†…å®¹
        "Quotes_v2",                          # åå†…å®¹
        "Semantic Quotes",                    # åå†…å®¹
        "Bible Memory Verse Flashcard",       # åå†…å®¹
        "Cigars",                             # åå†…å®¹
        "Feku Json",                          # æ‹¼å†™å¥‡æ€ª
        "Africa-Api ",                        # æ‹¼å†™å¥‡æ€ª
        "FastAPI Project",                    # æµ‹è¯•é¡¹ç›®
        "Lorem Ipsum Api",                    # å ä½ã€æµ‹è¯•
        "Fake Data Generator",                # æµ‹è¯•ã€ç”Ÿæˆå™¨
        "Seeding Data",                       # æµ‹è¯•ã€ç”Ÿæˆå™¨
        "Diablo4 Smartable",                  # å°ä¼—ã€åå¨±ä¹
        "Api plaque immatriculation SIV",     # å°ä¼—ã€æ‹¼å†™æ··ä¹±
        "Sign Hexagram",                      # åå†…å®¹ã€æ¨¡ç³Š
        "ğŸ”¥ All-In-One Crypto Swiss Knife ğŸš€", # èŠ±å“¨ã€ç¨³å®šæ€§å·®
        "Most expensive NFT artworks",        # åå†…å®¹ã€éé€šç”¨
        "Top NFT Collections",                # åå†…å®¹ã€éé€šç”¨
        "Rich NFT API + Metadata",            # åå†…å®¹ã€éé€šç”¨
        "Blur",                               # å°ä¼— NFT å¹³å°
        "Chain49",                            # å°ä¼—ã€æ¨¡ç³Š
        "Crypto Gem Finder",                  # å°ä¼—ã€æ¨¡ç³Š
        "Yandex Video API",                   # å°ä¼—å¹³å°
        "Yoonit",                             # å°ä¼—ã€æ¨¡ç³Š
        "Mobile-Phones",                      # åå·¥å…·ã€æ¨¡ç³Š
        "Scraper's Proxy",                    # åå·¥å…·ã€æ¨¡ç³Š
        "Open Brewery DB",                    # å°ä¼—ã€æ¨¡ç³Š
        "Leetcode Compensation",              # å°ä¼—ä¸“ç”¨
        "Awesome RSS",                        # åå†…å®¹ã€æ¨¡ç³Š
        "Lowest Bins Api",                     # å°ä¼—ã€æ¨¡ç³Š
        "Indian Names",                             # åå†…å®¹
        "dummyData",                                # æµ‹è¯•ç”Ÿæˆå™¨
        "Payment card numbers generator",           # ç”Ÿæˆå™¨
        "Fake Identity Generator",                  # ç”Ÿæˆå™¨
        "AI Random User Generator",                 # ç”Ÿæˆå™¨
        "Randomizer",                               # æµ‹è¯•ã€ç”Ÿæˆå™¨
        "Random User by API-Ninjas",                # ç”Ÿæˆå™¨
        "Emotional Poem",                           # åå†…å®¹
        "Cat Facts",                                # åå¨±ä¹
        "Historical Figures by API-Ninjas",         # åå†…å®¹
        "Railway Periods",                          # å°ä¼—ã€æ¨¡ç³Š
        "CHAT GPT AI BOT",                          # å·¥å…·æ‹¼æ¥ã€åç¦»æ•°æ®
        "BlockIt",                                  # æ‹¼å†™æ¨¡ç³Š
        "LBC Shark",                                # æ‹¼å†™æ¨¡ç³Š
        "PMI Jateng",                               # å°ä¼—ã€æ‹¼å†™æ¨¡ç³Š
        "BreachDirectory",                          # å°ä¼—ã€æ¨¡ç³Š
        # "Wayback machine domain archived lookup",   # å°ä¼—ã€æ¨¡ç³Š
        "Book",                                     # å°ä¼—ã€åå†…å®¹
        "NIV Bible",                                # å®—æ•™ã€åå†…å®¹
        "Barcodes",                                 # åå·¥å…·ã€æ¨¡ç³Š
        "Refactor numbers in human readable form like 1K or 1M", # å°å·¥å…·
        # "Genderizeio",                              # å°å·¥å…·ã€æ¨¡ç³Š
        "Railway Periods",                          # å°ä¼—ã€æ¨¡ç³Š
        # "Business email compromise (BEC) API",      # å°ä¼—ã€æ¨¡ç³Š
        # "Cloudflare bypass",                        # åå·¥å…·ã€éé€šç”¨
        "IP to Income",                             # å°ä¼—ã€æ¨¡ç³Š
        "Uers API",                                 # æ‹¼å†™é”™è¯¯ï¼ˆåº”è¯¥æ˜¯ Usersï¼Ÿï¼‰
        "SA Rego Check",                            # å°ä¼—ã€åœ°åŒºä¸“ç”¨
        "Indonesian National Identity Card Validator", # å°ä¼—ã€åœ°åŒºä¸“ç”¨
        "Cek ID PLN PASCA DAN PRA BAYAR",          # å°ä¼—ã€åœ°åŒºä¸“ç”¨
        "Indonesia Hotspot and Fire Location Data", # å°ä¼—ã€åœ°åŒºä¸“ç”¨
        # "Opencage geocoder",                        # å°ä¼—ã€æ¨¡ç³Š
        "AI detection",                             # å°å·¥å…·ã€æ¨¡ç³Š
        "Webit QR Code",                            # å°å·¥å…·
        "QR Code Generator API",                     # å°å·¥å…·
        "PlantWise",                               # å°ä¼—ã€ç”¨é€”æ¨¡ç³Š
        "Animals by API-Ninjas",                   # åå¨±ä¹
        "Dogs by API-Ninjas",                      # åå¨±ä¹
        "Cats by API-Ninjas",                      # åå¨±ä¹
        "Quotes by API-Ninjas",                    # åå†…å®¹
        "Thesaurus by API-Ninjas",                 # åå†…å®¹
        "Gloppo Fake API",                         # æµ‹è¯•ã€ä¼ªæ•°æ®
        "Ultimate password generator",             # ç”Ÿæˆå™¨
        "Unique Username Generator By Pizza API",  # ç”Ÿæˆå™¨
        "EAN13 Code Generator API",                # ç”Ÿæˆå™¨
        "GS1-Code128 Generator",                   # ç”Ÿæˆå™¨
        "BaseConverterAPI",                        # å°å·¥å…·ã€ç”Ÿæˆå™¨
        "Lorem Ipsum by API-Ninjas",               # ç”Ÿæˆå™¨ã€ä¼ªæ•°æ®
        "4D Dream Dictionary",                     # åå†…å®¹ã€å¨±ä¹
        "MetaAPI Mindfulness Quotes",              # åå†…å®¹
        "Lootero",                                 # æ‹¼å†™æ¨¡ç³Š
        "Sample API",                              # æµ‹è¯•ã€ä¼ªæ•°æ®
        "JoJ Web Search",                          # æ‹¼å†™æ¨¡ç³Š
        "Messages",                                # å°ä¼—ã€æ¨¡ç³Š
        "Person App",                              # å°ä¼—ã€æ¨¡ç³Š
        "Jiosaavn",                                # å°ä¼—ã€åœ°åŒºä¸“ç”¨
        "Italian Pharmacy",                        # å°ä¼—ã€åœ°åŒºä¸“ç”¨
        "Mzansi Loadshedding Api",                 # å°ä¼—ã€åœ°åŒºä¸“ç”¨
        "WA Rego Check",                           # å°ä¼—ã€åœ°åŒºä¸“ç”¨
        # "Car Verification Nigeria",                # å°ä¼—ã€åœ°åŒºä¸“ç”¨
        "Indian Mobile info",                      # å°ä¼—ã€åœ°åŒºä¸“ç”¨
        # "Vietnamese News",                         # å°ä¼—ã€åœ°åŒºä¸“ç”¨
        # "MagicEden",                               # å°ä¼—ã€æ¨¡ç³Š
        "SnapChat Story",                          # å°ä¼—ã€æ¨¡ç³Š
        "Diagnostics Code List",                   # å°ä¼—ã€æ¨¡ç³Š
        "Crops",                                   # å°ä¼—ã€æ¨¡ç³Š
        "Books",                                   # åå†…å®¹
        "Hedonometer",                             # å°ä¼—ã€æ¨¡ç³Š
        "Tokenizer",                               # å°å·¥å…·ã€éæ•°æ®
        "File Extension",                          # å°å·¥å…·ã€éæ•°æ®
        "Scrape for me",                           # æ¨¡ç³Šæ‹¼å†™
        "Request Boomerang"                        # å°ä¼—ã€ç”¨é€”æ¨¡ç³Š
    ]
    tools_to_remove_lower = set(t.lower() for t in data_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)

    target_category = "Movies"
    # åˆ é™¤9ä¸ªå·¥å…·
    # åˆ é™¤åŸå› æ€»ç»“ï¼š
    # 1ï¸âƒ£ åå­—æ¨¡ç³Šã€æ‹¼å†™æ··ä¹±æˆ–çœ‹ä¸å‡ºç”¨é€”ï¼ˆåƒ DAILY OVRLL ç³»åˆ—ï¼Œç¼–å·ä¸€å †ï¼Œçœ‹ä¸æ‡‚ï¼‰
    # 2ï¸âƒ£ æ˜æ˜¾æ˜¯æµ‹è¯•/æ ·æœ¬å·¥å…·ï¼ˆå¦‚ Abir82 Bollywood Recommendationsï¼Œçœ‹èµ·æ¥æ˜¯ä¸ªäººæˆ–å†…éƒ¨æµ‹è¯•é¡¹ç›®ï¼‰
    # 3ï¸âƒ£ ä¸ Movies ç±»åˆ«å…³ç³»å¼±æˆ–ä¸æ˜ç¡®ï¼ˆå¦‚ Playphrase.meï¼Œè™½å’Œå½±è§†æœ‰å…³ä½†åè¯­è¨€ç‰‡æ®µï¼Œä¸æ˜¯æ ¸å¿ƒå½±è§†å·¥å…·ï¼‰
    movies_tools_to_remove = [
        "DAILY OVRLL 0822202130334",  # åå­—æ··ä¹±ï¼Œçœ‹ä¸å‡ºå…·ä½“ç”¨é€”
        "DAILY OVRLL 0822202141203",  # åå­—æ··ä¹±ï¼Œçœ‹ä¸å‡ºå…·ä½“ç”¨é€”
        "DAILY OVRLL 0822202130418",  # åå­—æ··ä¹±ï¼Œçœ‹ä¸å‡ºå…·ä½“ç”¨é€”
        "DAILY OVRLL 0822202130837",  # åå­—æ··ä¹±ï¼Œçœ‹ä¸å‡ºå…·ä½“ç”¨é€”
        "DAILY OVRLL 0822202143542",  # åå­—æ··ä¹±ï¼Œçœ‹ä¸å‡ºå…·ä½“ç”¨é€”
        "DAILY OVRLL 0822202140642",  # åå­—æ··ä¹±ï¼Œçœ‹ä¸å‡ºå…·ä½“ç”¨é€”
        "DAILY OVRLL 0822202124848",  # åå­—æ··ä¹±ï¼Œçœ‹ä¸å‡ºå…·ä½“ç”¨é€”
        "Abir82 Bollywood Recommendations",  # æµ‹è¯•æ€§è´¨ï¼Œç–‘ä¼¼ä¸ªäººé¡¹ç›®ï¼Œä¸æ˜¯æ­£å¼API
        "Playphrase.me"  # åè¯­è¨€å­¦ä¹ ç‰‡æ®µï¼Œå’Œç”µå½±æ•°æ®æˆ–æµåª’ä½“å…³ç³»å¼±
    ]
    tools_to_remove_lower = set(t.lower() for t in movies_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Video_Images"
    # åˆ é™¤15ä¸ªå·¥å…·
    video_images_tools_to_remove = [
        "tes",  # åå­—æ¨¡ç³Šï¼Œçœ‹ä¸å‡ºç”¨é€”
        "nowyAPI",  # ç–‘ä¼¼æµ‹è¯•æˆ–ä¸ªäººé¡¹ç›®ï¼Œåå­—æ¨¡ç³Š
        "Quality Porn",  # è‰²æƒ…å†…å®¹ï¼Œä½ä¼˜å…ˆï¼Œå¯é æ€§å·®
        "Alt Bichinhos",  # åå­—æ€ªå¼‚ï¼ŒæŸ¥ä¸åˆ°å…·ä½“ç”¨é€”
        "james",  # åå­—æ¨¡ç³Šï¼Œçœ‹ä¸å‡ºç”¨é€”
        "amir1",  # æµ‹è¯•æ€§è´¨ï¼Œä¸ªäººé¡¹ç›®
        "ykapi",  # æµ‹è¯•æ€§è´¨ï¼Œåå­—çœ‹ä¸å‡ºç”¨é€”
        "Mission Creation",  # æµ‹è¯•æ€§è´¨æˆ–ä¸ªäººé¡¹ç›®
        "Pattern Monster",  # å›¾æ¡ˆç”Ÿæˆï¼Œåè®¾è®¡ï¼Œä¸æ˜¯è§†é¢‘/å›¾ç‰‡API
        "Thai Lottery Result Image",  # å½©ç¥¨å›¾åƒï¼Œå’Œè§†é¢‘å›¾ç‰‡å¤„ç†å…³ç³»å¼±
        "Porn gallery",  # è‰²æƒ…å†…å®¹ï¼Œä½ä¼˜å…ˆï¼Œå¯é æ€§å·®
        "Unofficial Icons8 Search",  # éå®˜æ–¹æ¥å£ï¼Œå¯èƒ½ä¸ç¨³å®š
        "Random anime img",  # éšæœºåŠ¨æ¼«å›¾åƒï¼Œå¨±ä¹æ€§é«˜ä½†ç”¨å¤„æ¨¡ç³Š
        "MlemAPI",  # åå­—æ€ªå¼‚ï¼Œçœ‹ä¸å‡ºç”¨é€”
        "Astro Gallery"  # å æ˜Ÿå›¾åƒï¼Œåå¨±ä¹ï¼Œä¸æ˜¯ä¸»æµè§†é¢‘å›¾ç‰‡å·¥å…·
    ]
    tools_to_remove_lower = set(t.lower() for t in video_images_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)



    target_category = "Financial"
    # åˆ é™¤12ä¸ªå·¥å…·
    financial_tools_to_remove = [
        "Smile",  # åå­—æ¨¡ç³Šï¼Œçœ‹ä¸å‡ºç”¨é€”
        "ClearDil",  # åå­—æ¨¡ç³Šï¼ŒæŸ¥ä¸åˆ°ç”¨é€”
        "Short",  # åå­—å¤ªæ¨¡ç³Šï¼Œçœ‹ä¸å‡ºç”¨é€”
        "I am rich",  # å™±å¤´æ€§è´¨å·¥å…·ï¼Œéé‡‘èå®ç”¨å·¥å…·
        "1p Challenge",  # ç©å…·æ€§è´¨ï¼Œéé‡‘èå®ç”¨å·¥å…·
        "Luhn algorithm",  # ä¿¡ç”¨å¡æ ¡éªŒç®—æ³•ï¼Œå’Œé‡‘èAPIä¸»çº¿å…³ç³»å¼±
        "Number2Words",  # æ•°å­—è½¬æ–‡å­—ï¼Œæ³›ç”¨å·¥å…·ï¼Œä¸æ˜¯é‡‘èä¸“å±
        "Number2Text",  # æ•°å­—è½¬æ–‡å­—ï¼Œæ³›ç”¨å·¥å…·ï¼Œä¸æ˜¯é‡‘èä¸“å±
        "Consulta de boleto",  # å°ä¼—ç¥¨æ®æŸ¥è¯¢ï¼ŒåŒºåŸŸæ€§å¤ªå¼º
        "RedStone",  # åå­—æ¨¡ç³Šï¼ŒæŸ¥ä¸åˆ°ç”¨é€”
        "Crypto Update Live",  # åå­—åƒä¿¡æ¯æµï¼Œä¸æ˜¯APIæˆ–å·¥å…·
        "CryptoInfo"  # åå­—æ¨¡ç³Šï¼Œå’Œå·²ä¿ç•™åŠ å¯†å·¥å…·é‡å¤
    ]
    tools_to_remove_lower = set(t.lower() for t in financial_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)



    target_category = "Media"
    # åˆ é™¤10ä¸ªå·¥å…·
    media_tools_to_remove = [
        "NewApi",  # åå­—æ¨¡ç³Šï¼Œçœ‹ä¸å‡ºç”¨é€”
        "convm",  # åå­—æ¨¡ç³Šï¼Œçœ‹ä¸å‡ºç”¨é€”
        "Colorful",  # åå­—æ¨¡ç³Šï¼Œçœ‹ä¸å‡ºç”¨é€”
        "public-url-share",  # åå­—æ¨¡ç³Šï¼Œçœ‹ä¸å‡ºç”¨é€”
        "riordanverse-api",  # å°ä¼—ç²‰ä¸å‘APIï¼Œä¸»çº¿å…³è”å¼±
        "Baby Pig Pictures",  # ç©å…·æ€§è´¨ï¼Œå¯çˆ±å›¾ç‰‡ï¼Œéåª’ä½“ä¸»çº¿å·¥å…·
        "Music Trivia",  # å°å‹å¨±ä¹å·¥å…·ï¼Œéä¸»çº¿åª’ä½“å·¥å…·
        "Easy QR Code Generator",  # æ³›ç”¨äºŒç»´ç å·¥å…·ï¼Œä¸åª’ä½“æ— å…³
        "getQRcode",  # æ³›ç”¨äºŒç»´ç å·¥å…·ï¼Œä¸åª’ä½“æ— å…³
        "AOL On Network"  # æŸ¥è¯¢ä¸åˆ°å¯é ç”¨é€”
    ]
    tools_to_remove_lower = set(t.lower() for t in media_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)



    target_category = "eCommerce"
    # åˆ é™¤18ä¸ªå·¥å…·ï¼Œæœ€ç»ˆåˆ é™¤17ä¸ª
    ecommerce_tools_to_remove = [
        "rttrt",  # åå­—æ¯«æ— æ„ä¹‰ï¼Œåƒéšæ‰‹æ•²çš„æµ‹è¯•
        "Swagger PetStore",  # æ˜æ˜¾æ˜¯APIç¤ºä¾‹ï¼Œä¸æ˜¯å®é™…ç”µå•†å·¥å…·
        "Simple TaxRate Retrieval",  # åªæ˜¯ç®€å•ç¨ç‡æŸ¥æ‰¾ï¼Œå’Œç”µå•†ç›´æ¥æ— å…³
        "Comany Details Search Online",  # å…¬å¸è¯¦æƒ…æœç´¢ï¼Œåå·¥å•†æ³¨å†Œç±»
        "GST Number Search by Name and PAN",  # ç¨å·æŸ¥è¯¢ï¼Œä¸è´­ç‰©æ— å…³
        "Leo Github API Scraper",  # Githubå·¥å…·ï¼Œä¸ç”µå•†å®Œå…¨ä¸ç›¸å…³
        "Github API Scraper",  # Githubå·¥å…·ï¼Œä¸ç”µå•†å®Œå…¨ä¸ç›¸å…³
        "Dungy Amazon Data Scraper",  # æ‹¼å†™å¥‡æ€ªï¼Œæ¥æºä¸æ˜
        "PPOB",  # åå­—å«ç³Šä¸æ¸…ï¼Œçœ‹ä¸å‡ºå…·ä½“ç”¨é€”
        "natural milk",  # å¬èµ·æ¥åƒæ˜¯äº§å“è¯ï¼Œä¸åƒæ˜¯APIå·¥å…·
        "Product",  # åå­—å¤ªæ¨¡ç³Šï¼Œæ¯«æ— å¯ç”¨æ€§
        "DigiXpress",  # æ‹¼å†™æ··ä¹±ï¼Œçœ‹ä¸å‡ºç”¨é€”
        "sellytics",  # åå­—æ‹¼å†™å¥‡æ€ªï¼ŒæŸ¥ä¸åˆ°å…·ä½“ç”¨é€”
        "E-commerce Delivery Status",  # å·¥å…·åå­—æ¨¡ç³Šï¼Œç¼ºä¹æ˜ç¡®ä½œç”¨æè¿°
        "Barcode",  # å·¥å…·å¤ªç®€å•ã€ç”¨é€”æ¨¡ç³Š
        "Makeup",  # å•ä¸€äº§å“ç±»ï¼Œç¼ºä¹é€šç”¨æ€§
        "Appibase",  # åå­—ä¸æ¸…æ¥šç”¨é€”ï¼Œä¹ŸæŸ¥ä¸åˆ°è¯¦ç»†èµ„æ–™
        "Get and Compate products allover the web"  # æ‹¼å†™é”™è¯¯ï¼ˆCompateï¼‰ï¼Œå·¥å…·è´¨é‡å­˜ç–‘
    ]
    tools_to_remove_lower = set(t.lower() for t in ecommerce_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)



    target_category = "Sports"
    # åˆ é™¤22ä¸ªå·¥å…·
    sports_tools_to_remove = [
        "test opta",  # æ˜æ˜¾æ˜¯æµ‹è¯•å·¥å…·
        "football test",  # æ˜æ˜¾æ˜¯æµ‹è¯•å·¥å…·
        "Satellite API",  # ä¸ä½“è‚²æ— å…³ï¼Œå«æ˜Ÿå·¥å…·
        "elvar",  # åå­—æ··ä¹±ï¼Œçœ‹ä¸å‡ºç”¨é€”ï¼Œå·²æµ‹è¯•ï¼Œä¸å¯ç”¨
        "adere",  # åå­—æ··ä¹±ï¼Œçœ‹ä¸å‡ºç”¨é€”
        "All data",  # åå­—æ¯«æ— æ„ä¹‰
        "score",  # åå­—å¤ªæ¨¡ç³Šï¼Œæ— æ³•åˆ¤æ–­ç”¨é€”
        "AllScores",  # åå­—å¤ªæ¨¡ç³Šï¼Œæ— æ³•åˆ¤æ–­ç”¨é€”
        "SportifyAPI",  # æ‹¼å†™ç±»ä¼¼ Spotifyï¼Œä½†å†…å®¹æ··ä¹±ï¼Œå·²æµ‹è¯•ï¼Œä¸å¯ç”¨
        "Gold Standard Sports",  # ç©ºæ³›åå­—ï¼Œçœ‹ä¸å‡ºå…·ä½“åŠŸèƒ½
        "Decathlon Sport Places",  # åå¥èº«åœºåœ°ï¼Œéä½“è‚²æ•°æ®ç±»
        "2PEAK.com Dynamic TRAINING PLANS for cycling running and Triathlon",  # åä¸ªäººè®­ç»ƒè®¡åˆ’ï¼Œä¸æ˜¯ä½“è‚²æ•°æ®APIï¼Œéœ€è¦å•ç‹¬çš„key
        "Metrx Factory",  # åå­—æ··ä¹±ï¼ŒæŸ¥ä¸åˆ°å…·ä½“ç”¨é€”
        # "SportScore",  # åå­—æ¨¡ç³Šï¼Œä¸æ˜ç¡®
        "90 Mins",  # åå­—å¤ªå£è¯­åŒ–ï¼Œæ— æ³•åˆ¤æ–­ç”¨é€”
        "Zeus API",  # åå­—æ¨¡ç³Šï¼Œçœ‹ä¸å‡ºä¸ä½“è‚²å…³ç³»
        "TransferMarkt DB",  # ä¸ TransferMarket é‡å¤
        "sport_v2",  # ç‰ˆæœ¬å·æ··ä¹±ï¼Œä¸æ˜ç¡®
        # "sportapi",  # åå­—ç¬¼ç»Ÿï¼Œä¸å…·ä½“
        "msport",  # åå­—æ¨¡ç³Šï¼Œçœ‹ä¸å‡ºç”¨é€”ï¼Œå·²æµ‹è¯•ï¼Œä¸å¯ç”¨
        # "IceHockeyApi",  # ä¸ Ice Hockey Data / NHL API ç­‰å·¥å…·é‡å¤
        "Match APi"  # åå­—æ‹¼å†™é”™è¯¯ï¼Œå·¥å…·è´¨é‡å­˜ç–‘
    ]
    tools_to_remove_lower = set(t.lower() for t in sports_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)



    target_category = "Email"
    # åˆ é™¤18ä¸ªå·¥å…·ï¼Œæœ€ç»ˆåˆ é™¤17ä¸ª
    email_tools_to_remove = [
        "MatinApi",  # åå­—æ··ä¹±ã€æ— æ³•å®šä½ç”¨é€”
        "apimail10",  # æµ‹è¯•å·¥å…·ï¼Œåå­—æ··ä¹±
        "account verifyer",  # æ‹¼å†™é”™è¯¯ï¼Œå·²æµ‹è¯•ï¼Œè¿æ¥è¶…æ—¶
        "Email Validator_v2",  # é‡å¤ç‰ˆæœ¬ï¼Œä¿ç•™ä¸»å·¥å…·
        "Email Validator_v3",  # é‡å¤ç‰ˆæœ¬ï¼Œä¿ç•™ä¸»å·¥å…·
        "Email validator_v5",  # é‡å¤ç‰ˆæœ¬ï¼Œä¿ç•™ä¸»å·¥å…·
        "Email Validator_v9",  # é‡å¤ç‰ˆæœ¬ï¼Œä¿ç•™ä¸»å·¥å…·
        "Email Validation_v3",  # é‡å¤åŠŸèƒ½
        "Verify Email",  # é‡å¤åŠŸèƒ½
        "Email Verifier/Validator",  # é‡å¤åŠŸèƒ½
        "Email Address Validator",  # é‡å¤åŠŸèƒ½
        "Email Existence Validator",  # é‡å¤åŠŸèƒ½
        "Emails Validator",  # é‡å¤åŠŸèƒ½
        "Emails Verifier",  # é‡å¤åŠŸèƒ½
        "Disposable Email Validation",  # é‡å¤åŠŸèƒ½
        "Email Validator_v3",  # é‡å¤åˆ—å‡º
        "Email API",  # ç¬¼ç»Ÿåå­—ï¼Œæ— æ˜ç¡®åŠŸèƒ½
        # "E-mail Check Invalid"  # åå­—ç¬¼ç»Ÿï¼Œè´¨é‡å­˜ç–‘
    ]
    tools_to_remove_lower = set(t.lower() for t in email_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)



    target_category = "Mapping"
    # åˆ é™¤13ä¸ªå·¥å…·
    mapping_tools_to_remove = [
        "Dargan",  # åå­—æ··ä¹±ã€ç”¨é€”ä¸æ˜ï¼Œæ²¡æœ‰è¯¥å·¥å…·
        "peta",  # åå­—æ··ä¹±ã€ç”¨é€”ä¸æ˜
        "Magical Taske",  # åå­—æ¨¡ç³Šã€æ— èƒŒæ™¯
        "Verify PAN Aadhaar link_v2",  # ä¸åœ°ç†æ— å…³ï¼Œæ˜¯å°åº¦èº«ä»½éªŒè¯å·¥å…·
        # "Geocode - Forward and Reverse",  # é‡å¤åŠŸèƒ½ï¼Œä¿ç•™æˆç†Ÿå·¥å…·
        # "Forward & Reverse Geocoding",  # é‡å¤åŠŸèƒ½ï¼Œä¿ç•™æˆç†Ÿå·¥å…·
        "Reverse Geocode Locator (U.S)",  # åŒºåŸŸæ€§å¤ªçª„ï¼Œä¿ç•™å…¨çƒå·¥å…·ï¼Œæ²¡æœ‰è¯¥å·¥å…·
        "Compare Route Names",  # åŠŸèƒ½ç‹­çª„ï¼Œè´¨é‡å­˜ç–‘
        # "smart locations",  # æ¨¡ç³Šåå­—ã€æ— èƒŒæ™¯
        # "City List",  # æ¨¡ç³ŠåŠŸèƒ½ï¼Œè´¨é‡å­˜ç–‘
        "Be Zips",  # æ¨¡ç³ŠåŠŸèƒ½ï¼Œè´¨é‡å­˜ç–‘ï¼Œè¯¥å·¥å…·æ”¶è´¹
        # "MapToolkit",  # æ¨¡ç³ŠåŠŸèƒ½ï¼Œè´¨é‡å­˜ç–‘
        # "Offline MapTiles"  # æ¨¡ç³Šç”¨é€”ï¼Œé‡å¤ MapTiles å·¥å…·
    ]
    tools_to_remove_lower = set(t.lower() for t in mapping_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)



    target_category = "Finance"
    # åˆ é™¤34ä¸ªå·¥å…·
    finance_tools_to_remove = [
        "Hryvna Today",  # åœ°åŒºè´§å¸ï¼Œä»…ä¹Œå…‹å…°ï¼Œä¸å…·æ™®éä»·å€¼
        "Optimism",  # å¤ªæ¨¡ç³Šï¼Œåå­—åƒåŒºå—é“¾é¡¹ç›®ï¼Œä¸åƒAPIå·¥å…·
        "Kiann_Options_SABR",  # çœ‹ä¼¼ä¸ªäººé¡¹ç›®æˆ–æµ‹è¯•
        "Kiann_Options_Project",  # çœ‹ä¼¼ä¸ªäººé¡¹ç›®æˆ–æµ‹è¯•
        "JoJ Finance",  # æ‹¼å†™æ€ªå¼‚ã€ç”¨é€”ä¸æ˜
        "sundayfinance",  # çœ‹ä¼¼ä¸ªäººä¾§é¡¹ç›®ï¼Œä¿¡æ¯æ¨¡ç³Š
        "Crypto grana",  # æ‹¼å†™æ€ªå¼‚ï¼Œåƒä¸ªäººå°é¡¹ç›®
        "walletapi.cloud",  # å¤ªæ³›ï¼Œæ¥æºå’Œç”¨é€”æ¨¡ç³Š
        "Palmy Investing API",  # æŸ¥ä¸åˆ°æ¥æºï¼Œå¯ä¿¡åº¦ä½
        "Date Calculator",  # å®Œå…¨ä¸é‡‘èæ— å…³
        "Global Flight Data",  # ä¸ Finance ç±»åˆ«ä¸åŒ¹é…ï¼ˆèˆªç­æ•°æ®ï¼‰
        "Currency Quake",  # åå­—å¤ªå¥‡æ€ªï¼Œåƒæ¸¸æˆæˆ–ä¸ªäººé¡¹ç›®
        "investing financial stocks",  # åå­—åƒå…³é”®è¯å †ç Œï¼Œæ‹¼å†™å¥‡æ€ª
        "G - Finance",  # åå­—å¤ªç®€ç•¥æ¨¡ç³Š
        "Qvantana",  # æ‹¼å†™å¥‡æ€ªã€ç”¨é€”ä¸æ˜
        "Quotient",  # åå­—æ³›ç”¨ï¼Œé‡‘èå…³ç³»æ¨¡ç³Š
        "Is This Coin A Scam",  # è¯´æ³•æ¨¡ç³Šï¼Œåƒè¯ˆéª—æ£€æµ‹ï¼Œä¸æ˜¯æ ‡å‡†API
        "Litecoin Wallet",  # é’±åŒ…å®¢æˆ·ç«¯ï¼Œä¸æ˜¯APIï¼Œä¸”åæŠ€æœ¯
        "360MiQ",  # åå­—æ¨¡ç³Šï¼ŒæŸ¥ä¸åˆ°å…¬å¼€é‡‘èAPIä¿¡æ¯
        "Fake Credit Card Number Generator API",  # æ˜æ˜¾æµ‹è¯•/ç”Ÿæˆä¼ªé€ æ•°æ®ï¼Œä¸åˆè§„
        "MathAAS",  # çº¯æ•°å­¦è®¡ç®—æœåŠ¡ï¼Œä¸Financeæ— å…³
        "Credit Card Number Validator",  # æœ‰ä¸“é—¨ç”¨é€”ï¼Œä½†åå­—å¤ªå®½æ³›ï¼Œå¯èƒ½ä¸ä¸“æ³¨Finance
        "ISLAMICOIN",  # ä¸æ˜APIï¼Œåå­—åƒé¡¹ç›®åï¼Œå¯ä¿¡åº¦ä½
        "Test_v3",  # æ˜æ˜¾æµ‹è¯•å·¥å…·ï¼Œç‰ˆæœ¬å·æš—ç¤º
        "Fake Credit Card Generator ",  # ä¸å‰é¢é‡å¤ï¼Œä¼ªé€ æ•°æ®å·¥å…·
        "Ethereum random address generator. ETH key pairs generator",  # çº¯å¯†é’¥ç”Ÿæˆå·¥å…·ï¼Œä¸æ˜¯è´¢ç»API
        "tokenlist",  # åå­—è¿‡äºæ³›ï¼Œæ— æ³•ç¡®å®šé‡‘èAPI
        "Crypto Asset Cold Wallet Create",  # çº¯é’±åŒ…åˆ›å»ºå·¥å…·ï¼Œéæ•°æ®æ¥å£
        "Direct Debit Managed Service",  # çœ‹ä¼¼ä¸šåŠ¡ç³»ç»Ÿï¼Œä¸åƒAPIå·¥å…·
        "RetrieveUSTaxRate",  # åå­—ç¬¼ç»Ÿï¼Œæ²¡æœ‰å…¬å¼€è¯¦ç»†èµ„æ–™
        "MS Finance",  # åå­—å¤ªç®€å•æ¨¡ç³Šï¼Œæ— æ³•ç¡®è®¤æ¥æº
        "Armatic",  # ä¸ªäººå°é¡¹ç›®æˆ–ä¸æ˜API
        "Involve Thailand FX Rates",  # åŒºåŸŸæ€§å°ä¼—APIï¼Œèµ„æ–™ä¸å…¨
        "Routing Number Bank Lookup"  # å·¥å…·æ€§è´¨è¿‡äºä¸“ä¸€ï¼Œä¸”æœ‰ç±»ä¼¼æ›´ä¼˜é€‰é¡¹
    ]
    tools_to_remove_lower = set(t.lower() for t in finance_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Health_and_Fitness"
    # åˆ é™¤4ä¸ªå·¥å…·
    health_tools_to_remove = [
        "Scoring Tables API",  # åç§°å¤ªæ³›ï¼Œæ— æ³•åˆ¤æ–­å…·ä½“å¥åº·åº”ç”¨
        "selector-tipo-consultas",  # æ‹¼å†™æ··ä¹±ï¼Œéè‹±è¯­ï¼Œæ¨¡ç³Šç”¨é€”
        "fastingcenters",  # åç§°è¿‡äºæ¨¡ç³Šï¼Œä¸ç¡®å®šæ˜¯å¦å¥åº·ç›¸å…³APIï¼Œå·²æµ‹è¯•ï¼Œä¸å¯ç”¨
        "Horostory"  # åç§°ä¸å¥åº·æ— å…³ï¼Œå¯èƒ½æ˜¯æ˜Ÿåº§ç±»å†…å®¹
    ]
    tools_to_remove_lower = set(t.lower() for t in health_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Travel"
    # åˆ é™¤18ä¸ªå·¥å…·ï¼Œåˆ é™¤äº†17ä¸ª
    travel_tools_to_remove = [
        "52 In Kicks",  # æ‹¼å†™æ··ä¹±ï¼Œæ— æ„ä¹‰
        "Tsaboin Cams",  # æ‹¼å†™æ··ä¹±ï¼Œç–‘ä¼¼æµ‹è¯•
        "ASR Hub",  # åå­—æ¨¡ç³Šï¼Œä¸æ˜ç¡®
        "funtrip",  # åå­—æ— æ„ä¹‰ï¼Œæ— æ³•åˆ¤æ–­ç”¨é€”
        # "borders",  # å¤ªæ³›ï¼Œæ— æ—…æ¸¸æœåŠ¡å±æ€§
        "VOO",  # æ¨¡ç³Šæ— æ„ä¹‰
        "StreetNarrator",  # ä¸æ˜ç¡®ç”¨é€”
        "Airports Info (Î±)",  # alphaæµ‹è¯•ç‰ˆï¼Œå·²æµ‹è¯•ï¼Œè¿æ¥è¶…æ—¶   
        "Flight _v2",  # æ‹¼å†™ä¸è§„èŒƒï¼Œé‡å¤å«ç³Š
        "Flight , Airline Consolidator, Flight Aggregator",  # åç§°é‡å¤ä¸”è¡¨è¾¾æ··ä¹±
        "flight | flight aggregator",  # åç§°é‡å¤ä¸”ä¸è§„èŒƒ
        "Turkey Public Holidays",  # è™½å±å‡æœŸä½†åéæ—…æ¸¸æœåŠ¡ï¼Œæ²¡æœ‰è¯¥å·¥å…·
        "Travelopro",  # åå­—ä¸æ˜ï¼Œæ— å…¬å¼€èµ„æ–™
        "Travelo Pro",  # åå­—ä¸æ˜ï¼Œæ— å…¬å¼€èµ„æ–™
        "Get_Ticket_Information",  # åç§°ä¸ä¸“ä¸šï¼Œä¸”æ— è¯¦ç»†è¯´æ˜
        "BiggestCities",  # ä¸â€œBiggest Citiesâ€é‡å¤ï¼Œä¸”æ— åŒºåˆ«
        "world cities by homicide rate",  # è´Ÿé¢å±æ€§ï¼Œä¸é€‚åˆæ—…æ¸¸å·¥å…·
        "Ranked Crime Cities"  # åŒä¸Š
    ]
    tools_to_remove_lower = set(t.lower() for t in travel_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Database"
    # åˆ é™¤42ä¸ªå·¥å…·
    database_tools_to_remove = [
        "aaaa",  # åå­—æ¨¡ç³Šæ— æ„ä¹‰
        "Summery",  # æ‹¼å†™é”™è¯¯ï¼Œæ„ä¹‰ä¸æ˜
        "Roman Gods By Pizza API",  # ä¸ç›¸å…³ï¼Œå†…å®¹åç¦»æ•°æ®åº“ä¸»é¢˜
        "Portfolio",  # å¤ªæ¨¡ç³Šï¼Œä¸æ˜ç¡®ç”¨é€”
        "SuggestUse",  # ä¸æ˜ç¡®ç”¨é€”
        "TEAS",  # åå­—æ— è¯´æ˜
        "HSN TSN",  # æ‹¼å†™æ··ä¹±ï¼Œå†…å®¹ä¸æ˜
        "expense data",  # åå­—è¿‡äºæ¨¡ç³Š
        "Quadro de sÃ³cios CPF/CNPJ",  # éè‹±æ–‡ä¸”æ— æ˜ç¡®ç”¨é€”è¯´æ˜
        "veiculos-api",  # æ‹¼å†™ä¸è§„èŒƒï¼Œç¼ºè¯´æ˜
        "Mocking Rock ",  # æ— å…³ä¸”åå­—å¥‡æ€ª
        "Taekwondo_Athlete_World_Ranking",  # ä¸ç›¸å…³ï¼Œä½“è‚²ç±»éæ•°æ®åº“
        "Watch Database",  # åå­—æ¨¡ç³Š
        "Lista de empresas por segmento",  # éè‹±æ–‡ä¸”æ— è¯´æ˜
        "siteDomain",  # ä¸æ˜ç¡®
        "Domain Reputation",  # åŠŸèƒ½åç½‘ç»œå®‰å…¨ï¼Œéæ•°æ®åº“æ ¸å¿ƒ
        "fwd-api",  # æ¨¡ç³Šæ— æ„ä¹‰
        "Python Libraries tst",  # æ˜æ˜¾æµ‹è¯•
        "get Mood",  # å†…å®¹ä¸æ˜ï¼Œç–‘ä¼¼æµ‹è¯•
        "Data Breach Checker",  # åå®‰å…¨ç±»ï¼Œä¸æ ¸å¿ƒæ•°æ®åº“
        "Indian RTO's Names Search ",  # å†…å®¹ä¸æ˜ä¸”æ‹¼å†™æ··ä¹±
        "Complete Criminal Checks Offender Data",  # å†…å®¹åæ³•å¾‹ï¼Œéæ•°æ®åº“API
        "Customer",  # è¿‡äºæ¨¡ç³Š
        "TEST",  # æµ‹è¯•
        "Women in Tech",  # å†…å®¹æ— å…³
        "Real_Estate_Heroku",  # åå­—æ¨¡ç³Šï¼Œä¸æ˜ç¡®
        "gcfen",  # æ‹¼å†™æ— æ„ä¹‰
        "hhside",  # æ‹¼å†™æ— æ„ä¹‰
        "Voter Card Verifications",  # éæ ¸å¿ƒæ•°æ®åº“
        "car code",  # å†…å®¹ä¸æ˜
        "gsaauction",  # åå­—ä¸æ˜ï¼Œç–‘ä¼¼éæ•°æ®åº“
        "Winget API",  # åå­—ä¸æ•°æ®åº“æ— å…³
        "Dati Comuni",  # éè‹±æ–‡ä¸”å†…å®¹ä¸æ˜
        "capitall_fitness",  # åå­—å¥‡æ€ªï¼Œä¸æ•°æ®åº“æ— å…³
        "Response WebHook",  # åŠŸèƒ½åé€šä¿¡éæ•°æ®åº“
        "Test1",  # æµ‹è¯•
        "Legend of Takada Kenshi",  # åå­—æ— æ„ä¹‰ï¼Œä¸ç›¸å…³
        "Student",  # è¿‡äºæ¨¡ç³Š
        "ICMAI Verification",  # å¯èƒ½æ˜¯éªŒè¯éæ•°æ®åº“
        "Card Databse",  # æ‹¼å†™é”™è¯¯ï¼Œä¸”å†…å®¹ä¸æ¸…
        "testapi2",  # æµ‹è¯•
        "Chattydata",  # åå­—æ— æ˜ç¡®ç”¨é€”
        "Joke Test",  # æµ‹è¯•
        "testGetApi",  # æµ‹è¯•
        "Geo_Coder_Dev",  # å¼€å‘ç‰ˆæœ¬ç–‘ä¼¼æµ‹è¯•
        "classes",  # è¿‡äºæ¨¡ç³Š
        "GetTempMail"  # é‚®ä»¶ä¸´æ—¶å·¥å…·ï¼Œéæ•°æ®åº“ç±»
    ]

    tools_to_remove_lower = set(t.lower() for t in database_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Education"
    # åˆ é™¤28ä¸ªå·¥å…·
    education_tools_to_remove = [
        "paultest",  # æµ‹è¯•å·¥å…·
        "apiDeveloper",  # æµ‹è¯•å·¥å…·
        "TestAPI",  # æµ‹è¯•å·¥å…·
        "Test_Crypto_Api",  # æµ‹è¯•å·¥å…·
        "APIGabin",  # æµ‹è¯•å·¥å…·
        "aftab",  # åå­—æ— æ„ä¹‰
        "mony",  # åå­—æ— æ„ä¹‰
        "yosi",  # åå­—æ— æ„ä¹‰
        "kittichai",  # åå­—æ— æ„ä¹‰
        "nguyenthanhduy178.tk",  # æ‹¼å†™å¥‡æ€ªï¼Œæ— è¯´æ˜
        "SevenTraderAPI",  # äº¤æ˜“ç±»ï¼Œéæ•™è‚²
        "weather",  # æ°”è±¡ç±»
        "weatherJS",  # æ°”è±¡ç±»
        "weather_v3",  # æ°”è±¡ç±»
        "message-api",  # åé€šä¿¡ï¼Œéæ•™è‚²
        "futboleta",  # è¶³çƒç¥¨åŠ¡ï¼Œä¸ç›¸å…³
        "COVID19PH",  # å…¬å…±å«ç”Ÿï¼Œéæ•™è‚²
        "democracia",  # å†…å®¹åæ”¿æ²»ï¼Œéæ•™è‚²
        "todo",  # åå­—æ¨¡ç³Šï¼Œéæ•™è‚²
        "hellonext",  # å†…å®¹æ¨¡ç³Šï¼Œéæ•™è‚²
        "nail",  # ä¸æ•™è‚²æ— å…³
        "lm_API",  # åå­—æ¨¡ç³Š
        "Safe Exam",  # å®‰å…¨ç±»ï¼Œéå­¦ä¹ å†…å®¹ï¼Œæ²¡æœ‰è¯¥å·¥å…·
        "Samyutam Eduction",  # æ‹¼å†™é”™è¯¯ä¸”æ— è¯´æ˜
        "sekolah",  # éè‹±æ–‡åï¼Œç¼ºå°‘ä¸Šä¸‹æ–‡ï¼Œéœ€è¦å•ç‹¬çš„key
        "fachaApi",  # åå­—æ— æ„ä¹‰
        "tapzulecountry",  # åå­—æ‹¼å†™æ··ä¹±
        "ask-ai"  # å†…å®¹æ¨¡ç³Šï¼Œéæ˜ç¡®æ•™è‚²ç”¨é€”ï¼Œå·²æµ‹è¯•ï¼Œè¿æ¥è¶…æ—¶
    ]

    tools_to_remove_lower = set(t.lower() for t in education_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Science"
    # åˆ é™¤7ä¸ªå·¥å…·
    science_tools_to_remove = [
        "teste",  # æµ‹è¯•å·¥å…·
        "test",  # æµ‹è¯•å·¥å…·
        "Irene",  # åå­—æ— æ„ä¹‰
        "manatee jokes",  # ç¬‘è¯ï¼Œä¸æ˜¯ç§‘å­¦
        "Al-Quran",  # å®—æ•™å†…å®¹
        "Yawin Indian Astrology",  # å æ˜Ÿï¼Œéç§‘å­¦
        "Astrologer"  # å æ˜Ÿï¼Œéç§‘å­¦
    ]

    tools_to_remove_lower = set(t.lower() for t in science_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Monitoring"
    # åˆ é™¤8ä¸ªå·¥å…·
    monitoring_tools_to_remove = [
        "Counter",  # åå­—å¤ªæ¨¡ç³Š
        "OTP",  # ä¸ç®—ç›‘æµ‹å·¥å…·
        "Patient",  # åå­—æ¨¡ç³Šï¼Œä¸çŸ¥æ‰€æŒ‡
        "Certficate",  # æ‹¼å†™é”™è¯¯
        "SearchingWebRequest",  # æµ‹è¯•æˆ–æ¨¡ç³Šç”¨é€”
        "Screenshot Maker",  # æˆªå›¾å·¥å…·ï¼Œä¸æ˜¯ç›‘æ§
        # "Youtube classification api",  # åˆ†ç±»åˆ†æï¼Œä¸æ˜¯ç›‘æ§
        "Plerdy"  # åå‘åˆ†æå·¥å…·ï¼Œä¸æ˜¯ç›´æ¥ç›‘æ§
    ]

    tools_to_remove_lower = set(t.lower() for t in monitoring_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Translation"
    # åˆ é™¤8ä¸ªå·¥å…·
    translation_tools_to_remove = [
        "01",  # æ•°å­—ä»£å·ï¼Œæ¨¡ç³Š
        "13f918yf19o1t1f1of1t9",  # æ··ä¹±å­—ç¬¦ä¸²
        "navicon1",  # åå­—æ¨¡ç³Š
        "Nitro",  # åå­—æ¨¡ç³Šï¼Œçœ‹ä¸å‡ºç”¨é€”
        "English synonyms",  # åŒä¹‰è¯æŸ¥è¯¢ï¼Œä¸æ˜¯ç¿»è¯‘
        "Translator",  # è¿‡äºæ³›åŒ–ï¼Œæ— æ³•åŒºåˆ†ï¼Œæ²¡æœ‰è¯¥å·¥å…·
        "Translate it",  # è¿‡äºæ³›åŒ–ï¼Œæ— æ³•åŒºåˆ†ï¼Œæ²¡æœ‰è¯¥å·¥å…·
        "Translate Language"  # è¿‡äºæ³›åŒ–ï¼Œæ— æ³•åŒºåˆ†ï¼Œæ²¡æœ‰è¯¥å·¥å…·
    ]

    tools_to_remove_lower = set(t.lower() for t in translation_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Tools"
    # åˆ é™¤21ä¸ªå·¥å…·
    tools_tools_to_remove = [
        "dimondevosint",  # æ‹¼å†™æ··ä¹±ï¼Œä¸çŸ¥ç”¨é€”
        "teamriverbubbles random utilities",  # åå­—æ··ä¹±ï¼Œæ³›åŒ–å·¥å…·é›†åˆ
        "ğŸ‘‹ Demo Project_v12",  # æ¼”ç¤ºé¡¹ç›®
        "Placeholder text API for your application",  # å ä½å·¥å…·
        "echo-api",  # å ä½æˆ–æµ‹è¯•
        "SimpleEcho",  # æµ‹è¯•æˆ–å›å£°å·¥å…·
        "ProbablyThese",  # åå­—æ¨¡ç³Š
        "Plus One",  # åå­—æ¨¡ç³Š
        "core_js",  # æ¨¡å—åï¼Œä¸æ˜¯ç‹¬ç«‹å·¥å…·
        "QR Code API_v33",  # QRå·¥å…·é‡å¤ï¼Œç•™æ¸…æ™°ç‰ˆæœ¬
        "QR Code_v18",  # åŒä¸Š
        "QR Code API_v67",  # åŒä¸Š
        "QR Code API_v92",  # åŒä¸Š
        "Custom QR Code with Logo_v2",  # å¤ªç»†åˆ†ã€ä½ç‰ˆæœ¬ï¼Œç•™ä¸»å·¥å…·
        "Variable Size QR Code API",  # åå­—ä¸æ¸…æ™°
        "Quick QR Code Generator",  # æ³›åŒ–åå­—
        "TVB QR Code",  # æŒ‡å‘ç‰¹å®šç”¨é€”ï¼Œæ³›åŒ–åœºæ™¯ç”¨ä¸ä¸Š
        "ProbablyThese",  # æ¨¡ç³Šã€ä¸çŸ¥ç”¨é€”
        # "Anchor Data Scrapper",  # ä¸çŸ¥å…·ä½“ç”¨é€”ï¼Œåå­—æ¨¡ç³Š
        "UptoSite Link Shortener",  # ä¸æ¸…æ™°ã€ä¸å¸¸ç”¨
        "ExplorArc's Password Generation API",  # éä¸»æµã€åå­—ä¸æ¸…æ™°
        "story",  # åå­—æ¨¡ç³Šï¼Œä¸çŸ¥ç”¨é€”ï¼Œæ²¡æœ‰è¯¥å·¥å…·
        "Todo",  # å ä½æˆ–æµ‹è¯•å·¥å…·
        "Proof of concept",  # æµ‹è¯•å·¥å…·
        "QuickMocker",  # æµ‹è¯•å·¥å…·
        "Starline Telematics",  # ä¸ç›¸å…³ï¼Œç”¨é€”æ¨¡ç³Š
        "Joe Rogan Quote Generator",  # ä¸ç›¸å…³ï¼Œæç¬‘ç”¨é€”
        "Shakespeare Translator",  # è¶£å‘³å·¥å…·ï¼Œç”¨å¤„ä¸å¤§
        "Words World",  # æ¨¡ç³Šï¼Œä¸çŸ¥ç”¨é€”
        "QR code_v8",  # é‡å¤ã€ä½ç‰ˆæœ¬
        "QR Code API_v6",  # é‡å¤ã€ä½ç‰ˆæœ¬
        "QR Code API_v119",  # é‡å¤ã€ç‰ˆæœ¬ä¹±
        "QRLink API",  # åå­—æ¨¡ç³Šï¼Œé‡å¤ï¼Œæ²¡æœ‰è¯¥å·¥å…·
        "QR-Generator-Api",  # é‡å¤ï¼Œå·²æµ‹è¯•ï¼Œè¿æ¥è¶…æ—¶
        "QR Code Generator API_v6",  # é‡å¤ã€ä½ç‰ˆæœ¬
        # "QRickit QR Code QReator",  # åå­—æ··ä¹±
        "Simple & Cheap QR CODE GENERATOR",  # åå­—æ··ä¹±
        "Bar QR Code Generator",  # é‡å¤
        "QR code generator with multiple datatypes .",  # åå­—æ¨¡ç³Š
        "qrcode-generator-base64",  # ç»†åˆ†é‡å¤å·¥å…·
        "QR Code Wizard"  # é‡å¤ã€åå­—æ¨¡ç³Š
    ]
    tools_to_remove_lower = set(t.lower() for t in tools_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Text_Analysis"
    # åˆ é™¤18ä¸ªå·¥å…·
    text_analysis_tools_to_remove = [
        "gruite",  # åå­—æ¨¡ç³Š
        "SpeakEasy",  # åå­—æ¨¡ç³Š
        "Fast Reading",  # æ¨¡ç³Šç”¨é€”
        "Hello world_v2",  # æµ‹è¯•å·¥å…·
        "testingsunlife",  # æµ‹è¯•å·¥å…·
        # "Google Translate",  # é‡å¤
        "Google Translate_v2",  # é‡å¤
        # "Profanity Filter",  # é‡å¤
        "Profanity Filter_v2",  # é‡å¤
        "Sentiment Analysis Service",  # é‡å¤
        "Sentimental Analysis_v2",  # é‡å¤
        "Sentiment Analysis_v12",  # é‡å¤
        "Sentiment analysis_v13",  # é‡å¤
        "PAN Card OCR",  # OCRç±»ï¼Œå‰”é™¤
        "Philippines Voter Card OCR",  # OCRç±»
        "Philippines Passport OCR",  # OCRç±»
        "Philippines Driving License OCR",  # OCRç±»
        "Philippines TIN OCR",  # OCRç±»
        "National ID Vietnam OCR",  # OCRç±»
        "Voter Card OCR",  # OCRç±»
        "Philippines Social Security OCR",  # OCRç±»
        "Driving License OCR"  # OCRç±»
    ]
    tools_to_remove_lower = set(t.lower() for t in text_analysis_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)



    target_category = "Advertising"
    # åˆ é™¤37ä¸ªå·¥å…·
    advertising_tools_to_remove = [
        "20211230 testing upload swagger",  # æµ‹è¯•å·¥å…·
        "Putreq",  # æµ‹è¯•/å ä½
        "route-precedence-test-1",  # æµ‹è¯•
        "testing",  # æµ‹è¯•
        "PublicAPITestingInbox",  # æµ‹è¯•
        "pe-demo",  # æµ‹è¯•
        "PetstoreRateLimit",  # æµ‹è¯•
        "Test_v2",  # æµ‹è¯•
        "MultipleTeamsCallingTest",  # æµ‹è¯•
        "ThisshouldbeFREE",  # æµ‹è¯•
        "petstore blitz",  # æµ‹è¯•
        "PrivatePublicAPI",  # æµ‹è¯•
        "FreePlanwithHardLimit",  # æµ‹è¯•
        "versioning-free",  # æµ‹è¯•
        "FOOTBALL_API_KEY",  # æµ‹è¯•
        "March4",  # æµ‹è¯•/æ¨¡ç³Š
        "httpbin",  # æµ‹è¯•å·¥å…·
        "underscore test",  # æµ‹è¯•
        "Hello World",  # å ä½
        "test",  # æµ‹è¯•
        "hello_v2",  # æµ‹è¯•
        "Test1",  # æµ‹è¯•
        "ssssss",  # æµ‹è¯•/ä¹±ç 
        "Test_v5",  # æµ‹è¯•
        "test_v6",  # æµ‹è¯•
        "versions-paid",  # æµ‹è¯•
        "ddd",  # æ¨¡ç³Š
        "a",  # å•å­—æ¯
        "asd",  # æ¨¡ç³Š
        "lets",  # æ¨¡ç³Š
        "16e0e5f7a076c2f62a2e41f6b5b99d37e5b9b25e",  # ä¹±ç 
        "Frederick",  # æ¨¡ç³Š
        "Free IP Geolocation",  # éå¹¿å‘Šç±»ï¼Œéœ€è¦å•ç‹¬è®¾ç½®key
        "Abstract IP geolocation",  # éå¹¿å‘Šç±»ï¼Œéœ€è¦å•ç‹¬è®¾ç½®key
        "JobsApi",  # éå¹¿å‘Šç±»ï¼Œå·²åºŸå¼ƒ
        # "Autosub"  # éå¹¿å‘Šç±»
    ]
    tools_to_remove_lower = set(t.lower() for t in advertising_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Weather"
    # åˆ é™¤17ä¸ªå·¥å…·
    weather_tools_to_remove = [
        "Testing for My Use",  # æµ‹è¯•
        "WeatherTest",  # æµ‹è¯•
        "Test",  # æµ‹è¯•
        "Test_v2",  # æµ‹è¯•
        "daily limit check",  # æµ‹è¯•
        "weather_v14",  # æµ‹è¯•
        "weather_v13",  # æµ‹è¯•
        "Weather_v6",  # æµ‹è¯•
        "123",  # æµ‹è¯•/æ¨¡ç³Š
        "History",  # åå­—å¤ªå®½æ³›ï¼Œæ‰¾ä¸åˆ°
        "Forecast",  # åå­—å¤ªå®½æ³›ï¼Œæ‰¾ä¸åˆ°
        "MagicMirror",  # æ¨¡ç³Š
        "OikoWeather",  # æ¨¡ç³Š
        "havo",  # æ¨¡ç³Š
        "Monitoring Syatem",  # æ‹¼å†™æ··ä¹±
        "CurrencyConverter"  # è·‘é¢˜å·¥å…·
    ]
    tools_to_remove_lower = set(t.lower() for t in weather_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "News_Media"
    # åˆ é™¤15ä¸ªå·¥å…·
    news_media_tools_to_remove = [
        "Test_v2",  # æµ‹è¯•
        "OneLike",  # æ¨¡ç³Š
        "papercliff",  # æ¨¡ç³Š
        "Green Gold",  # æ¨¡ç³Š
        "Goverlytics",  # æ¨¡ç³Šï¼Œå·²æµ‹è¯•ï¼Œä¸å¯ç”¨
        "depuertoplata",  # æ¨¡ç³Š
        "getMedia",  # æ¨¡ç³Š
        "Book Cover API",  # è·‘é¢˜
        # "Flixster",  # è·‘é¢˜
        "Movies details",  # è·‘é¢˜ï¼Œæ‰¾ä¸åˆ°
        "Online Movie Database",  # è·‘é¢˜
        "SB Weather",  # è·‘é¢˜
        "Football-API",  # è·‘é¢˜
        "PAC API"  # è·‘é¢˜
    ]
    tools_to_remove_lower = set(t.lower() for t in news_media_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Business_Software"
    # åˆ é™¤19ä¸ªå·¥å…·
    business_software_tools_to_remove = [
        "test2",  # æµ‹è¯•å·¥å…·
        "testapi_v2",  # æµ‹è¯•å·¥å…·
        "OPA-test",  # æµ‹è¯•å·¥å…·
        "demo",  # æµ‹è¯•/demoå·¥å…·
        "BogieApis",  # æµ‹è¯•/demoå·¥å…·
        "fffvfv",  # åå­—æ··ä¹±ï¼Œç”¨é€”ä¸æ˜
        "dathoang",  # åå­—æ··ä¹±ï¼Œç”¨é€”ä¸æ˜
        "aug13",  # åå­—æ··ä¹±ï¼Œç”¨é€”ä¸æ˜
        "sdfsdf_v2",  # åå­—æ··ä¹±ï¼Œç”¨é€”ä¸æ˜
        "HelloRold",  # åå­—æ··ä¹±ï¼Œç”¨é€”ä¸æ˜
        "newnew",  # åå­—æ··ä¹±ï¼Œç”¨é€”ä¸æ˜
        "My API 12345",  # åå­—æ··ä¹±ï¼Œç”¨é€”ä¸æ˜
        "ucinema",  # ä¸å•†åŠ¡è½¯ä»¶æ— å…³ï¼ˆå½±é™¢ï¼‰
        "Slot and Betting Games",  # ä¸å•†åŠ¡è½¯ä»¶æ— å…³ï¼ˆåšå½©ï¼‰
        "Find any IP address or Domain Location world wide",  # ä¸å•†åŠ¡è½¯ä»¶æ— å…³ï¼ˆçº¯åœ°ç†æŸ¥è¯¢ï¼‰
        "Logo",  # å°å·¥å…·ï¼ŒåŠŸèƒ½å¤ªå•ä¸€ï¼Œä¸ç®—å•†åŠ¡è½¯ä»¶
        "ShortLink",  # å°å·¥å…·ï¼ŒåŠŸèƒ½å¤ªå•ä¸€ï¼Œä¸ç®—å•†åŠ¡è½¯ä»¶
        "QuizApp",  # å°å·¥å…·ï¼ŒåŠŸèƒ½å¤ªå•ä¸€ï¼Œä¸ç®—å•†åŠ¡è½¯ä»¶
        # "B2BHint"  # æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­å¯é æ€§ï¼Œåå‘åˆ é™¤
    ]
    tools_to_remove_lower = set(t.lower() for t in business_software_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Gaming"
    # åˆ é™¤20ä¸ªå·¥å…·
    gaming_tools_to_remove = [
        "big89",  # åå­—æ··ä¹±ï¼Œç”¨é€”ä¸æ˜
        "HleBy6eK",  # åå­—æ··ä¹±ï¼Œç”¨é€”ä¸æ˜
        "a56219609685dd9033d060cdbb60093c",  # åå­—æ··ä¹±ï¼Œç”¨é€”ä¸æ˜
        "Fodase",  # åå­—æ··ä¹±ï¼Œç”¨é€”ä¸æ˜
        "Scott",  # åå­—æ··ä¹±ï¼Œç”¨é€”ä¸æ˜
        "StonxzyAPI",  # åå­—æ··ä¹±ï¼Œç”¨é€”ä¸æ˜
        "game",  # å ä½æˆ–æµ‹è¯•å
        "Plugin.proto",  # å ä½æˆ–æµ‹è¯•å
        "hitmen2",  # ç”¨é€”ä¸æ˜ï¼ŒæŸ¥ä¸åˆ°ä¿¡æ¯
        "GoTW",  # ç”¨é€”ä¸æ˜ï¼ŒæŸ¥ä¸åˆ°ä¿¡æ¯
        "Weeby",  # ç”¨é€”ä¸æ˜ï¼ŒæŸ¥ä¸åˆ°ä¿¡æ¯ï¼Œå·²æµ‹è¯•ï¼Œä¸å¯ç”¨
        "Aposta Ganha Aviator API",  # åšå½©ä¸‹æ³¨ç±»ï¼Œéä¸»æµæ¸¸æˆå·¥å…·
        "Vai de Bob Aviator API",  # åšå½©ä¸‹æ³¨ç±»ï¼Œéä¸»æµæ¸¸æˆå·¥å…·
        "Estrelabet Aviator API",  # åšå½©ä¸‹æ³¨ç±»ï¼Œéä¸»æµæ¸¸æˆå·¥å…·
        "Bet7k Aviator API",  # åšå½©ä¸‹æ³¨ç±»ï¼Œéä¸»æµæ¸¸æˆå·¥å…·
        "Simbrief - Get latest OFP",  # èˆªç©ºé£è¡Œè®¡åˆ’å·¥å…·ï¼Œåç¦»æ¸¸æˆä¸»é¢˜ï¼Œæ‰¾ä¸åˆ°
        "League Of Legends Champion Generator",  # LoL åŒç±»å·¥å…·å·²ä¿ç•™å¤šä¸ªï¼Œå»æ‰é‡å¤
        "CricketLiveApi",  # ä½“è‚²æ¯”åˆ†ç±»ï¼Œåç¦»ä¸»æµè§†é¢‘/ç”µå­æ¸¸æˆï¼Œå·²æµ‹è¯•ï¼Œè¿æ¥è¶…æ—¶
        # "Play to Earn Blockchain Games",  # åŒºå—é“¾æ¸¸æˆå°ä¼—å·¥å…·ï¼Œè´¨é‡å­˜ç–‘
        # "Trivia by API-Ninjas"  # å°å‹å·¥å…·ï¼Œè´¨é‡å­˜ç–‘
    ]
    tools_to_remove_lower = set(t.lower() for t in gaming_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Location"
    # åˆ é™¤25ä¸ªå·¥å…·
    location_tools_to_remove = [
        "BPS",  # åå­—æ¨¡ç³Šï¼Œçœ‹ä¸å‡ºç”¨é€”
        "Services",  # åå­—æ¨¡ç³Šï¼Œçœ‹ä¸å‡ºç”¨é€”
        "Location",  # åå­—æ¨¡ç³Šï¼Œå¤ªå®½æ³›
        "Location_v2",  # æµ‹è¯•æˆ–å ä½ï¼Œåå­—ä¸æ¸…æ¥š
        "Get IP Info_v2",  # æµ‹è¯•æˆ–å ä½ï¼Œåå­—æ¨¡ç³Š
        "get cities",  # åå­—æ¨¡ç³Šï¼ŒåŠŸèƒ½èŒƒå›´å¤ªå®½
        "https://ipfinder.io/",  # æ˜¯ç½‘å€ï¼Œä¸æ˜¯å·¥å…·å
        "IsItWater.com",  # ä¸ä½ç½®å…³ç³»å¼±ï¼Œæ›´åƒæ°´åŸŸä¿¡æ¯
        "Income by Zipcode",  # åæ”¶å…¥ç»Ÿè®¡ï¼Œä¸æ˜¯æ ¸å¿ƒå®šä½
        # "Feroeg - Reverse Geocoding",  # æ‹¼å†™æ··ä¹±ï¼Œä¸ä¼˜è´¨
        "Schweizer Postleitzahlen",  # è¿‡äºå°ä¼—åœ°åŒºï¼Œå·¥å…·é‡å¤
        "KFC locations",  # å“ç‰Œç‰¹å®šï¼Œä¸é€šç”¨
        "Nearby Tesla Superchargers",  # å“ç‰Œç‰¹å®šï¼Œä¸é€šç”¨
        "Find By UDPRN",  # å°ä¼—ï¼Œè‹±å›½é‚®æ”¿ä¸“ç”¨ç¼–ç ï¼Œé€šç”¨æ€§å·®
        # "Vessels",  # èˆ¹åªï¼Œä¸æ˜¯çº¯åœ°ç†ä½ç½®å·¥å…·
        "IP Directory",  # å«ä¹‰æ¨¡ç³Šï¼Œä¸æ˜ç¡®æ˜¯æŸ¥ä»€ä¹ˆ
        "Wyre Data",  # åå­—æ¨¡ç³Šï¼ŒæŸ¥ä¸åˆ°æ˜ç¡®ç”¨é€”
        "Partenaires Mobilis",  # æœ¬åœ°åŒ–ã€æ‹¼å†™æ€ªå¼‚ï¼Œä¸é€šç”¨
        "Referential",  # å¤ªæ¨¡ç³Šï¼Œçœ‹ä¸å‡ºå®šä½åŠŸèƒ½
        "BDapi",  # æ‹¼å†™æ¨¡ç³Šï¼Œç¼ºä¹æ˜ç¡®åŠŸèƒ½æè¿°
        "GeoWide",  # æ¨¡ç³Šï¼Œä¸æ˜ç¡®ç”¨é€”
        "CatchLoc",  # åå­—æ¨¡ç³Šï¼Œä¸æ¸…æ¥šå…·ä½“ç”¨é€”
        "MapReflex",  # åå­—æ¨¡ç³Šï¼Œä¸å¸¸è§æˆ–æŸ¥ä¸åˆ°
        # "Bng2latlong",  # å°ä¼—è‹±å›½åæ ‡è½¬æ¢ï¼Œé‡å¤åº¦é«˜
        "Itcooking.eu - IP Geolocation"  # åå­—æ··ä¹±ï¼Œä¸ä¼˜è´¨æ¥æº
    ]
    tools_to_remove_lower = set(t.lower() for t in location_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Social"
    # åˆ é™¤25ä¸ªå·¥å…·
    social_tools_to_remove = [
        "Socie",  # åå­—æ¨¡ç³Š
        "ABCR",  # åå­—æ¨¡ç³Š
        "IDD",  # åå­—æ¨¡ç³Š
        "MESCALC",  # åå­—æ¨¡ç³Š
        "Chuck Norris",  # ç¬‘è¯ç±»
        "Tronald Dump",  # ç¬‘è¯ç±»
        "Fortune Cookie",  # è¶£å‘³ç±»
        "Flirty words",  # è¶£å‘³ç±»
        "Real Love Calculator",  # è¶£å‘³ç±»
        "Marryme",  # è¶£å‘³ç±»
        "QUIZ",  # è¶£å‘³ç±»
        "Instagram_v2",  # ç‰ˆæœ¬é‡å¤ï¼Œä¿ç•™æœ€æ–°
        "Instagram_v3",  # ç‰ˆæœ¬é‡å¤ï¼Œä¿ç•™æœ€æ–°
        "Instagram_v6",  # ç‰ˆæœ¬é‡å¤ï¼Œä¿ç•™æœ€æ–°
        "Instagram_v7",  # ç‰ˆæœ¬é‡å¤ï¼Œä¿ç•™æœ€æ–°
        "Instagram_v9",  # ç‰ˆæœ¬é‡å¤ï¼Œä¿ç•™æœ€æ–°
        "Instagram_v10",  # ç‰ˆæœ¬é‡å¤ï¼Œä¿ç•™ç¨³å®šç‰ˆ
        "Olato Quotes",  # æ‹¼å†™æ€ªå¼‚ï¼Œå·²æµ‹è¯•ï¼Œä¸å¯ç”¨
        "Tweesky",  # æ‹¼å†™æ€ªå¼‚ï¼Œå·²æµ‹è¯•ï¼Œä¸å¯ç”¨
        "PeerReach",  # æ‹¼å†™æ€ªå¼‚ï¼Œå·²æµ‹è¯•ï¼Œè¿æ¥è¶…æ—¶
        "Popular languages",  # åè¯­è¨€ç»Ÿè®¡
        # "Jobs from remoteok",  # åæ‹›è˜
        "Instagram #1",  # å¥‡æ€ªå‘½å
        "Instagram Fast",  # å¥‡æ€ªå‘½å
        "Instagram Cheapest"  # å¥‡æ€ªå‘½å
    ]
    tools_to_remove_lower = set(t.lower() for t in social_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Search"
    # åˆ é™¤19ä¸ªå·¥å…·
    search_tools_to_remove = [
        "Fiverr Pro services",           # éæœç´¢ï¼ŒæœåŠ¡å¸‚åœº
        "TorrentHunt",                   # ä¸»é¢˜åç¦»ï¼ŒBTç§å­æœç´¢ï¼ŒèŒƒå›´åçª„ä¸”ä¸ç¨³å®š
        "VIN decoder",                  # è½¦è¾†VINè§£ç ï¼Œä¸æœç´¢ç±»åˆ«ä¸ç¬¦
        "Vehicle Ownership Cost",       # è½¦è¾†æˆæœ¬ä¼°ç®—ï¼Œéæœç´¢å·¥å…·
        "OPT-NC public docker images",  # æ‹¼å†™æ··ä¹±ï¼Œä¸ç›¸å…³ï¼Œè²Œä¼¼æµ‹è¯•æˆ–ä¸“ä¸šé•œåƒåº“
        "NFT Explorer",                 # éæœç´¢ç±»åˆ«ï¼ŒåŒºå—é“¾NFT
        "Emplois OPT-NC",               # åç§°ä¸æ˜ç¡®ï¼Œä¸”éé€šç”¨æœç´¢ç±»
        "Postali",                     # åå­—æ¨¡ç³Šï¼Œéš¾ä»¥ç¡®å®šç”¨é€”
        "DBU_API",                     # æ‹¼å†™æ¨¡ç³Šï¼Œæ— å…·ä½“è¯´æ˜ï¼Œç–‘ä¼¼æµ‹è¯•æˆ–ä¸“ä¸šå†…éƒ¨å·¥å…·
        "barcode.monster",             # æ¡ç ç›¸å…³ï¼Œéé€šç”¨æœç´¢
        "Front Page search engine",    # åç§°è¿‡äºé€šç”¨ï¼Œéš¾ä»¥åˆ¤å®šï¼Œä¸”æ— èµ„æ–™ï¼Œå·²æµ‹è¯•ï¼Œä¸å¯ç”¨
        "Netlas All-in-One Host",      # åç§°æ¨¡ç³Šï¼Œåå‘ä¸»æœºæˆ–ç½‘ç»œç®¡ç†ï¼Œä¸æ˜¯æœç´¢
        "ExplorArc's Link Finder",     # æ¨¡ç³Šå·¥å…·åï¼Œç¼ºä¹æ¸…æ™°ç”¨é€”è¯´æ˜ï¼Œå·²æµ‹è¯•ï¼Œä¸å¯ç”¨
        "UfU",                        # æ‹¼å†™æ··ä¹±ï¼Œæ— æ³•ç†è§£å«ä¹‰
        "Vehicle Market Value",        # è½¦è¾†å¸‚åœºä¼°å€¼ï¼Œéæœç´¢å·¥å…·
        "HotelApi",                   # é…’åº—APIï¼Œéæœç´¢ç±»
        "Question-Answered",          # åç§°æ¨¡ç³Šï¼Œä¸æ¸…æ¥šæ˜¯å¦æœç´¢
        "Postleitzahl zu Adresse",    # å¾·è¯­é‚®ç¼–è½¬åœ°å€å·¥å…·ï¼Œä¸“ä¸šæ€§å¼ºä¸”æ¨¡ç³Š
        "Searchhook"                  # æ‹¼å†™æ··ä¹±ï¼Œæ— æ³•æ˜ç¡®åˆ¤æ–­ç”¨é€”ï¼Œå·²æµ‹è¯•ï¼Œä¸å¯ç”¨
    ]
    tools_to_remove_lower = set(t.lower() for t in search_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Visual_Recognition"
    # åˆ é™¤6ä¸ªå·¥å…·
    visual_recognition_tools_to_remove = [
        "Parking places",              # è¯­ä¹‰æ¨¡ç³Šï¼Œä¸”ä¸æ˜æ˜¾æ˜¯è§†è§‰è¯†åˆ«å·¥å…·
        "Voltox OCR",                 # åç§°ä¸å¸¸è§ï¼Œç¼ºä¹å…¬å¼€èµ„æ–™æ”¯æŒï¼Œæ¨¡ç³Šä¸æ˜ï¼Œé”™è¯¯å·¥å…·å·²æµ‹è¯•
        "Fast Hcaptcha Solver",       # CAPTCHAè§£ç å™¨ï¼Œä¸æ˜¯è§†è§‰è¯†åˆ«èŒƒç•´
        "Fast Recaptcha V2 Solver",   # åŒä¸Šï¼ŒéªŒè¯ç ç ´è§£ï¼Œä¸å±äºè§†è§‰è¯†åˆ«
        "Auther Check",               # åç§°æ¨¡ç³Šï¼Œæ— æ³•åˆ¤å®šå…·ä½“ç”¨é€”
        "OCR - Separate Text From Images"  # è¯­ä¹‰é‡å¤ä¸”ä¸æ˜ç¡®ï¼Œå·²æœ‰OCRå·¥å…·è¦†ç›–
    ]
    tools_to_remove_lower = set(t.lower() for t in visual_recognition_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Transportation"
    # åˆ é™¤6ä¸ªå·¥å…·
    transportation_tools_to_remove = [
        "Datamo",                     # åç§°æ¨¡ç³Šï¼ŒåŠŸèƒ½ä¸æ˜
        "AP sample",                  # æ˜æ˜¾æµ‹è¯•/ç¤ºä¾‹å·¥å…·
        "FachaAPI",                   # åç§°æ¨¡ç³Šï¼Œç¼ºä¹æ˜ç¡®ç”¨é€”
        "OpenNWI",                   # åç§°ä¸æ˜ï¼Œéš¾ä»¥åˆ¤æ–­æ˜¯å¦ç›¸å…³
        "TrackingPackage",            # åç§°ä¸ç¬¦åˆäº¤é€šè¿è¾“æ ¸å¿ƒèŒƒç•´ï¼Œä¸”åŠŸèƒ½ä¸æ˜ï¼Œåº”å±äºç‰©æµ
        # "TimeTable Lookup "           # åç§°ä¸è§„èŒƒï¼Œæœ«å°¾æœ‰ç©ºæ ¼ä¸”ä¸å¤Ÿæ˜ç¡®
    ]
    tools_to_remove_lower = set(t.lower() for t in transportation_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Other"
    # åˆ é™¤52ä¸ªå·¥å…·
    other_tools_to_remove = [
        "pl1box1",                   # åç§°æ¨¡ç³Šï¼Œæ— æ˜æ˜¾ç”¨é€”
        "13",                       # æ— æ„ä¹‰æ•°å­—ï¼Œæ— æ³•åˆ¤æ–­
        "4Bro  - 1337X",            # åç§°æ¨¡ç³Šï¼Œå¯èƒ½ä¸æœç´¢ç«™æˆ–ç›—ç‰ˆç›¸å…³ï¼Œä¸åˆé€‚
        "Demo1",                    # æ˜æ˜¾æµ‹è¯•/æ¼”ç¤ºå·¥å…·
        "sample-app-config.json",   # é…ç½®æ–‡ä»¶ï¼Œä¸æ˜¯å·¥å…·
        "team petstore",            # åç§°æ¨¡ç³Šï¼Œä¸æ˜ç”¨é€”
        "quotsy",                   # æ‹¼å†™ä¸æ˜ï¼Œæ¨¡ç³Šç”¨é€”
        "JAK_API",                  # åç§°ä¸æ˜ç¡®
        "URLTEST",                  # æµ‹è¯•æ€§è´¨
        "erictestpet",              # æµ‹è¯•æ€§è´¨
        "Node Express API Tutorial",# æ•™ç¨‹æ€§è´¨ï¼Œä¸æ˜¯APIå·¥å…·
        "Most Exclusive API",       # åç§°æ¨¡ç³Šï¼Œç¼ºä¹æ˜ç¡®ç”¨é€”
        "myapi",                    # åç§°æ¨¡ç³Š
        "TestAPI_v4",               # æµ‹è¯•å·¥å…·
        "Darko Androcec Example",   # ç¤ºä¾‹æ€§è´¨
        "Fake users_v6",            # æµ‹è¯•/æ¼”ç¤ºæ•°æ®
        "Hello World",              # æµ‹è¯•/ç¤ºä¾‹æ€§è´¨
        "5970b9b3dcc757e61e53daec3e720974",  # æ— æ„ä¹‰å­—ç¬¦ä¸²
        "S-YTD",                    # åç§°æ¨¡ç³Šï¼Œä¸æ˜ç”¨é€”
        "Lab2",                     # æµ‹è¯•/æ¼”ç¤ºæ€§è´¨
        "csa_v2",                   # åç§°æ¨¡ç³Š
        "DAd",                      # åç§°æ¨¡ç³Š
        "PracticaUipath",           # åç§°æ¨¡ç³Šï¼Œä¸”Uipathé€šå¸¸éAPIå·¥å…·
        "toptalOnlineTest",         # æµ‹è¯•æ€§è´¨
        "katzion test",             # æµ‹è¯•æ€§è´¨
        "AI endpoint",              # åç§°æ¨¡ç³Š
        "Ignition",                 # åç§°æ¨¡ç³Š
        "Echo",                     # åç§°æ¨¡ç³Š
        "Heck Yes Markdown",        # ä¸å·¥å…·æ— å…³
        "Uros Kovcic",              # ä¸ªäººåï¼Œéå·¥å…·
        "getAssessments",           # åç§°æ¨¡ç³Š
        "RakutenSupportDefaultTeam",# ç»„ç»‡/å›¢é˜Ÿåï¼Œéå·¥å…·
        "backend",                  # é€šç”¨æœ¯è¯­ï¼Œæ¨¡ç³Š
        "TestApi_v2",               # æµ‹è¯•å·¥å…·
        "Testing",                  # æµ‹è¯•æ€§è´¨
        # "Calulator",                # æ‹¼å†™é”™è¯¯ï¼Œæ¨¡ç³Šç”¨é€”
        "Evaluate expression",      # è¿‡äºæ¨¡ç³Š
        # "Cors Proxy",               # ä»£ç†ç›¸å…³ï¼Œåéå·¥å…·æ€§è´¨
        "Test_v4",                  # æµ‹è¯•å·¥å…·
        "Test_v2",                  # æµ‹è¯•å·¥å…·
        # "Random Username Generate", # ç”¨é€”å¯ï¼Œä½†å› å…¶ä»–æµ‹è¯•å·¥å…·å¤ªå¤šï¼Œå¯ä¿ç•™ä¹Ÿå¯åˆ ï¼ˆè¿™é‡Œè§†ä¸¥æ ¼ç¨‹åº¦å†³å®šï¼‰
        "testApi",                  # æµ‹è¯•å·¥å…·
        "MyPersonal",               # ä¸ªäººåæˆ–æ¨¡ç³Šç”¨é€”
        "Testing Demo",             # æµ‹è¯•æ€§è´¨
        "TestAPI_v3",               # æµ‹è¯•å·¥å…·
        "haime-python-api",         # åç§°æ‹¼å†™é”™è¯¯ï¼Œæ¨¡ç³Šç”¨é€”
        "PragmavantApi",            # åç§°æ‹¼å†™æ¨¡ç³Šï¼Œä¸æ˜ç¡®
        "colegiosantaana",          # åœ°åæˆ–ç»„ç»‡åï¼Œä¸æ˜ç¡®
        "pl1box1",                  # é‡å¤ï¼Œæ¨¡ç³Šç”¨é€”
        "Quran Com"                 # å®—æ•™ç›¸å…³å†…å®¹ï¼Œå’ŒOtherç±»åˆ«å·¥å…·ç”¨é€”ä¸æ˜ç¡®
    ]
    tools_to_remove_lower = set(t.lower() for t in other_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Food"
    # åˆ é™¤20ä¸ªå·¥å…·
    food_tools_to_remove = [
        "Testing_v2",               # æµ‹è¯•å·¥å…·ï¼Œåå­—ä¸æ˜ç¡®
        "Auth",                     # è®¤è¯ç±»å·¥å…·ï¼Œä¸é£Ÿå“æ— å…³
        "Viva City Documentation",  # æ–‡æ¡£ï¼ŒéAPIå·¥å…·ï¼Œä¸”ç”¨é€”ä¸æ˜
        "postcap",                  # åå­—æ¨¡ç³Šï¼Œæ— æ³•åˆ¤æ–­ç”¨é€”
        "Payment",                  # æ”¯ä»˜ç±»ï¼Œä¸é£Ÿå“æ— å…³
        "CamRest676",               # åå­—æ¨¡ç³Šï¼Œæ— æ˜æ˜¾é£Ÿå“å…³è”
        "MyNewTestApi",             # æµ‹è¯•å·¥å…·
        "test1",                    # æµ‹è¯•å·¥å…·
        "Testing_v3",               # æµ‹è¯•å·¥å…·ï¼Œåå­—ä¸æ˜ç¡®
        "betaRecipes",              # æµ‹è¯•/æµ‹è¯•ç‰ˆ
        "Generic Food_v2",          # åç§°æ³›æ³›ï¼Œå¯èƒ½é‡å¤æˆ–æ— æ˜æ˜¾å·®å¼‚
        "Recipe_v2",                # ç‰ˆæœ¬è€æ—§ï¼Œä¿ç•™æœ€æ–°ç‰ˆæœ¬
        "Recipe_v3",                # ç‰ˆæœ¬è€æ—§ï¼Œä¿ç•™æœ€æ–°ç‰ˆæœ¬
        "Recipe_v4",                # é‡å¤ç‰ˆæœ¬ï¼Œè€ƒè™‘åˆå¹¶ï¼Œåˆ æ—§
        "Food Nutrional Data",      # æ‹¼å†™é”™è¯¯ï¼ˆNutritionalï¼‰ï¼Œä¸”å¯èƒ½é‡å¤
        "favoriteFoodApi",          # åå­—æ¨¡ç³Šï¼Œä¸å¤Ÿæ ‡å‡†
        "ComfyFood",                # åå­—ä¸å¤Ÿæ˜ç¡®ï¼Œä¸”æ— çŸ¥ååº¦
        "pizzaallapala",            # æ‹¼å†™æ··ä¹±ï¼Œæ— æ³•ç¡®å®šç”¨é€”
        "Store Groceries",          # ä¸å¤Ÿæ˜ç¡®ï¼Œå¯èƒ½ä¸é£Ÿå“åº“å­˜ç›¸å…³ä½†ä¿¡æ¯ä¸è¶³
        "Bespoke Diet Generator"    # åå­—è¾ƒé•¿ä¸”æ¨¡ç³Šï¼Œéä¸»æµæˆ–ä¸ç¡®å®šåŠŸèƒ½
    ]
    tools_to_remove_lower = set(t.lower() for t in food_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Entertainment"
    # åˆ é™¤42ä¸ªå·¥å…·
    entertainment_tools_to_remove = [
        "4D Results",                   # åå­—å«ç³Šï¼Œéš¾ç¡®å®šç”¨é€”
        "Minecraft-Forge-Optifine",     # æ¸¸æˆModå·¥å…·ï¼Œä¸æ˜¯APIå¨±ä¹å†…å®¹
        "mbar",                        # åå­—æ— æ„ä¹‰ï¼Œæ¨¡ç³Š
        "kast",                        # åå­—æ— æ„ä¹‰ï¼Œæ¨¡ç³Š
        "Dung Bui",                    # äººåæˆ–æ— æ„ä¹‰ï¼Œæ¨¡ç³Š
        "Pipotronic",                  # åå­—æ— æ„ä¹‰ï¼Œæ¨¡ç³Š
        "yurna",                      # åå­—æ— æ„ä¹‰ï¼Œæ¨¡ç³Š
        "Sholltna",                   # åå­—æ— æ„ä¹‰ï¼Œæ¨¡ç³Š
        "Testing",                    # æµ‹è¯•å·¥å…·
        "Interesting Facts API",      # åçŸ¥è¯†ç±»ï¼Œä¸æ˜¯çº¯å¨±ä¹
        "Text similarity calculator",# å·¥å…·ç±»ï¼Œéå¨±ä¹å†…å®¹
        "Direct Porn_v2",             # æˆäººå†…å®¹ï¼Œä¸”ç‰ˆæœ¬ä¸è§„èŒƒ
        "rapid-porn",                 # æˆäººå†…å®¹ï¼Œéæ­£è§„API
        "Porn Movies",                # æˆäººå†…å®¹
        "Ten Secrets About Mega888 Ios Download That Has Never Been Revealed For The Past Years", # åƒåœ¾æ¨å¹¿æ ‡é¢˜
        "69bd0c7193msh3c4abb39db3a82fp18c336jsn8470910ae9f0", # æ— æ„ä¹‰å­—ç¬¦ä¸²ï¼Œç–‘ä¼¼åƒåœ¾
        "DaddyJokes",                 # é‡å¤ç¬‘è¯å·¥å…·ï¼Œä¸”åä¸è§„èŒƒ
        "Joke1",                     # åç§°æ¨¡ç³Šï¼Œä½è´¨é‡
        "jokes ",                    # ç©ºæ ¼æ‹¼å†™ï¼Œä½è´¨é‡é‡å¤
        "cubiculus - managing LEGO set collection", # LEGOæ”¶è—å·¥å…·ï¼Œä¸å±äºå¨±ä¹API
        "Twitter video downloader mp4", # å·¥å…·ç±»ï¼Œéå¨±ä¹å†…å®¹
        "Facebook video downloader MP4",# å·¥å…·ç±»ï¼Œéå¨±ä¹å†…å®¹
        "Img to ASCII",              # å›¾åƒè½¬ASCIIï¼Œå·¥å…·ç±»éå¨±ä¹API
        "MagicMirrorAPI",            # ä¸ç›¸å…³
        "Allbet Online Casino  in Singapore", # æ˜æ˜¾åšå½©å¹¿å‘Šï¼Œä¸æ­£è§„
        "Follow Youtube Channel",    # è¿è¥å·¥å…·ï¼Œä¸æ˜¯APIå¨±ä¹å†…å®¹
        "mydailyinspiration",        # çµæ„Ÿå†…å®¹ï¼ŒåçŸ¥è¯†ç±»
        # "Would You Rather",          # æ¸¸æˆç±»é‡å¤ï¼Œåæ°”å°
        # "Comedy(KK)",                # åå­—ä¸ä¸“ä¸š
        "Random Yes/No",             # éšæœºå·¥å…·ï¼Œä¸æ˜¯å¨±ä¹API
        "Vadym-rock-paper-scissors-api", # æ¸¸æˆAPIå¤ªå°ä¼—ä¸”æ‹¼å†™ä¹±
        "Cash4Life",                 # å½©ç¥¨ç±»ï¼Œéä¸»æµå¨±ä¹API
        "Euro Millions",             # å½©ç¥¨ç±»ï¼Œéä¸»æµå¨±ä¹API
        "Lotto America",             # å½©ç¥¨ç±»ï¼Œéä¸»æµå¨±ä¹API
        "Fantasy 5",                 # å½©ç¥¨ç±»ï¼Œéä¸»æµå¨±ä¹API
        "New York Lottery",          # å½©ç¥¨ç±»ï¼Œéä¸»æµå¨±ä¹API
        "Casino related"             # å…¶ä»–åšå½©ç›¸å…³å·¥å…·ä¸€å¾‹å‰”é™¤ï¼Œä¿æŒå¥åº·å‘
    ]
    tools_to_remove_lower = set(t.lower() for t in entertainment_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)

    target_category = "Commerce"
    # åˆ é™¤26ä¸ªå·¥å…·
    commerce_tools_to_remove = [
        "sandbox mktplace eu  01 products",      # åå­—æ¨¡ç³Šï¼Œå«ç©ºæ ¼ä¸”ä¸è§„èŒƒ
        "sandbox ecombr com - 04 orders",        # åå­—æ··ä¹±ï¼Œsandboxæµ‹è¯•ç¯å¢ƒ
        "sandbox mktplace eu - 04 orders",       # åŒä¸Šï¼Œæµ‹è¯•ç¯å¢ƒ
        "sandbox ecombr com - 01 products",      # åŒä¸Šï¼Œæµ‹è¯•ç¯å¢ƒ
        "dd",                                   # æ— æ„ä¹‰ï¼Œåå­—æ¨¡ç³Š
        "Movives",                              # ç”µå½±ç›¸å…³ï¼Œä¸å±äºå•†åŠ¡
        "test pg prod",                         # æµ‹è¯•å·¥å…·
        "test",                                # æµ‹è¯•å·¥å…·
        "togo420",                             # åå­—æ— æ„ä¹‰
        "Test API",                            # æµ‹è¯•å·¥å…·
        "test_v3",                            # æµ‹è¯•å·¥å…·
        "JSMon",                              # åå­—æ— æ„ä¹‰
        "Test_v2",                            # æµ‹è¯•å·¥å…·
        "API1",                               # æ³›æ³›æ— ä¿¡æ¯
        "BrowserObject",                      # å¼€å‘ç›¸å…³ï¼Œéå•†åŠ¡
        "IP2Proxy",                          # ä»£ç†å·¥å…·ï¼Œéå•†åŠ¡
        "ClickbankUniversity",               # æ•™è‚²åŸ¹è®­ï¼Œä¸æ˜¯å·¥å…·
        "resumeAPI",                        # ç®€å†ç›¸å…³ï¼Œéå•†åŠ¡
        "Face Compare",                    # äººè„¸è¯†åˆ«ï¼Œéå•†åŠ¡
        "Inventory and eCommerce hosted and self-hosted solution",  # æè¿°æ³›æ³›ï¼Œä¸æ˜¯å…·ä½“API
        "Cartify",                        # åå­—ä¸æ¸…æ™°ï¼Œä¿¡æ¯å°‘
        # "Flance AliExpress",             # æ‹¼å†™ç–‘ä¼¼é”™è¯¯ï¼Œå¯ä¿¡åº¦ä½
        "HaloBiru.store",               # åº—é“ºåï¼ŒéAPIå·¥å…·
        "Azaprime",                    # ä¿¡æ¯ä¸æ˜ï¼Œåå­—ä¸æ¸…æ™°
        "789club New",                 # åå­—æ— æ„ä¹‰ï¼Œæ‚ä¹±
        "Amazon Live Data"             # å¯èƒ½é‡å¤Amazon_API_v2ï¼Œå†—ä½™
    ]
    tools_to_remove_lower = set(t.lower() for t in commerce_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Music"
    # åˆ é™¤28ä¸ªå·¥å…·
    music_tools_to_remove = [
        "kotak7",                               # åå­—æ— æ„ä¹‰
        "Miza",                                # åå­—æ— æ„ä¹‰
        "Latest Spotify Downloader",           # ç‰ˆæƒé£é™©å·¥å…·
        "MusiclinkssApi",                      # æ‹¼å†™é”™è¯¯ï¼Œåå­—ä¸æ¸…æ™°
        "MyAPI",                              # æ³›æ³›æ— ä¿¡æ¯
        # "L-yrics",                           # åå­—ä¸æ¸…æ™°
        "station",                           # æ³›æ³›ä¸”æ— æ„ä¹‰
        "getSongs",                         # æ³›æ³›æ— æ„ä¹‰
        # "MusicZone",                        # ä¸æ˜ç¡®
        "shoxbps",                         # åå­—æ— æ„ä¹‰
        "baixar musicas mp3 completas",    # ç‰ˆæƒé£é™©ï¼Œä¸”åå­—æ‹¼å†™æ‚ä¹±
        "deepsound",                       # ä¸æ˜ç¡®ï¼Œæ¨¡ç³Š
        "xmusic",                         # ä¸æ˜ç¡®
        # "melodyn",                        # ä¸æ˜ç¡®
        "RojMusic",                      # ä¸æ˜ç¡®
        "online-music",                  # åå­—æ¨¡ç³Šæ³›æ³›
        "Youtube MP3 Converter",          # ç‰ˆæƒé£é™©å·¥å…·
        "Bandamp Downloader API",         # ç‰ˆæƒé£é™©
        "ReverbNation Song Downloader",  # ç‰ˆæƒé£é™©
        "MP3 Downloader",                 # ç‰ˆæƒé£é™©
        "VkoorSound",                    # ä¸æ˜ç¡®
        "myPlayvv",                     # ä¸æ˜ç¡®
        "GG",                          # æ— æ„ä¹‰ç¼©å†™
        "Spotify _v2",                  # å‘½åä¸è§„èŒƒï¼Œå¸¦ç©ºæ ¼
        "Billboard-API",                # å†—ä½™ï¼Œä¿ç•™å…¶ä»–ç‰ˆ
        "Billboard API_v2",             # å†—ä½™ï¼Œä¿ç•™ä¸»ç‰ˆ
        "MusicAPI",                    # æ³›æ³›æ— å…·ä½“ä¿¡æ¯
        "247NaijaBuzz"                 # ä¸æ˜ç¡®ï¼Œåå­—éä¸»æµéŸ³ä¹å·¥å…·
    ]
    tools_to_remove_lower = set(t.lower() for t in music_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Business"
    # åˆ é™¤69ä¸ªå·¥å…·
    business_tools_to_remove = [
        "apfd",  # æ‹¼å†™æ¨¡ç³Šï¼Œä¸æ˜ç”¨é€”
        "Interceptor Sample",  # æ˜æ˜¾æµ‹è¯•å·¥å…·
        "token2go",  # åå­—æ¨¡ç³Š
        "DOMAINE nc",  # åå­—æ¨¡ç³Š
        "Ziff",  # åå­—æ¨¡ç³Š
        "Woo-temp",  # æ˜æ˜¾æµ‹è¯•å·¥å…·
        "acopaer",  # æ‹¼å†™æ¨¡ç³Š
        "PetStoreAPI2.0",  # ç±»ä¼¼æµ‹è¯•/demoå·¥å…·
        "TEXTKING Translation",  # ä¸å±äºå•†åŠ¡æ ¸å¿ƒ
        "SOTI Sync",  # åå­—ä¸æ¸…æ™°ï¼Œä¸šåŠ¡æ— å…³
        "Shwe 2D Live Api",  # ä¸ç›¸å…³å¨±ä¹å·¥å…·
        "mgs",  # æ‹¼å†™æ¨¡ç³Š
        "DaysAPI",  # ä½œç”¨ä¸æ¸…æ™°
        "Fake Brightcove",  # æ˜æ˜¾æµ‹è¯•æˆ–ä¼ªé€ 
        "Testing out Sharing w/ Rachael",  # æ˜æ˜¾æµ‹è¯•å·¥å…·
        "5ka_Porocila",  # åå­—æ¨¡ç³Šï¼Œéš¾ä»¥åˆ¤æ–­
        "000",  # æ— æ„ä¹‰åç§°
        "print",  # æ— æ„ä¹‰åç§°
        "news",  # ä¸šåŠ¡ä¸ç›¸å…³
        "hyhryh",  # æ‹¼å†™æ··ä¹±æ— æ„ä¹‰
        "KarenRecommends",  # ä¸ç›¸å…³æ¨èå·¥å…·
        "WRAWS Load Test",  # æ˜æ˜¾æµ‹è¯•
        "test_API_v2",  # æ˜æ˜¾æµ‹è¯•
        "test_v16",  # æ˜æ˜¾æµ‹è¯•
        "XTREAM",  # ä¸šåŠ¡ä¸ç›¸å…³
        # "'"/>><img src=x onerror=prompt(document.domain);>",  # æ¶æ„ä»£ç æˆ–æ— æ•ˆè¾“å…¥
        "constructioness",  # æ‹¼å†™é”™è¯¯ä¸”æ— æ„ä¹‰
        "test_v20",  # æ˜æ˜¾æµ‹è¯•
        "partydiva",  # ä¸æ˜ä¸šåŠ¡å·¥å…·
        "test",  # æ˜æ˜¾æµ‹è¯•
        "567 Live app 2022",  # ä¸šåŠ¡æ— å…³
        "TestPOCApi",  # æ˜æ˜¾æµ‹è¯•
        "Healthcaremailing",  # åå­—ä¸æ¸…æ™°ï¼Œç–‘ä¼¼éæ ¸å¿ƒä¸šåŠ¡
        "Test_API",  # æ˜æ˜¾æµ‹è¯•
        "hfghfgh",  # æ‹¼å†™æ··ä¹±
        "Ken",  # æ‹¼å†™ä¸æ˜ç¡®
        "prueba",  # è¥¿ç­ç‰™è¯­æµ‹è¯•
        "InsafEl",  # åå­—ä¸æ˜
        "enrich",  # åå­—æ¨¡ç³Š
        "11BET",  # èµŒåšç›¸å…³ï¼Œä¸šåŠ¡ä¸ç›¸å…³
        "denemeapisi",  # åœŸè€³å…¶è¯­æµ‹è¯•API
        "test apizzz",  # æ˜æ˜¾æµ‹è¯•
        "Test_v18",  # æ˜æ˜¾æµ‹è¯•
        "Rotating Proxies",  # æŠ€æœ¯æ”¯æŒï¼Œä¸æ˜¯ä¸šåŠ¡å·¥å…·
        "0MMO",  # åå­—æ¨¡ç³Š
        "b4c6577cb2msh7c15fca215f2c30p1f1717jsn998498c6865e",  # éä¸šåŠ¡å·¥å…·ï¼Œæ‚ä¹±å­—ç¬¦
        "My Bot",  # æµ‹è¯•æˆ–æ— å…³å·¥å…·
        "New Client",  # æ— æ„ä¹‰
        "Test_v14",  # æ˜æ˜¾æµ‹è¯•
        "Personas",  # ä¸æ¸…æ™°å·¥å…·
        # "eSignly",  # åå­—ä¸æ¸…æ™°ï¼Œéæ ¸å¿ƒä¸šåŠ¡
        "KUBET-",  # èµŒåšç›¸å…³
        "kassbet",  # èµŒåšç›¸å…³
        "789bettnet",  # èµŒåšç›¸å…³
        "ExplorArc's Internel Links Crawler",  # çˆ¬è™«éä¸šåŠ¡æ ¸å¿ƒ
        "FM_API_RELEASE v0.1",  # ç‰ˆæœ¬å·æµ‹è¯•
        "testpk",  # æ˜æ˜¾æµ‹è¯•
        "dxjewof",  # æ‹¼å†™æ— æ„ä¹‰
        "pss",  # æ— æ„ä¹‰
        "LD",  # åå­—æ¨¡ç³Š
        "My public interface",  # æ— æ˜ç¡®ä¸šåŠ¡å«ä¹‰
        "Test New Team",  # æµ‹è¯•å·¥å…·
        "123CACA",  # æ— æ„ä¹‰
        "ì˜¤ë¥˜",  # éŸ©æ–‡é”™è¯¯ï¼Œéä¸šåŠ¡å·¥å…·
        "Test_v3",  # æ˜æ˜¾æµ‹è¯•
        "1800 Printing Test",  # æ˜æ˜¾æµ‹è¯•
        "test1",  # æ˜æ˜¾æµ‹è¯•
        "anttdev 2",  # æµ‹è¯•æˆ–å¼€å‘ç”¨
        "qwe",  # æ— æ„ä¹‰
        "111",  # æ— æ„ä¹‰
        "Test Plan",  # æ˜æ˜¾æµ‹è¯•
        "czkjlj",  # æ— æ„ä¹‰
        "AE6888 Link vao nha cai AE688  2022"  # èµŒåšç›¸å…³å¹¿å‘Š
    ]
    tools_to_remove_lower = set(t.lower() for t in business_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Artificial_Intelligence_Machine_Learning"
    # åˆ é™¤6ä¸ªå·¥å…·
    ai_ml_tools_to_remove = [
        "test",  # æ˜æ˜¾æµ‹è¯•å·¥å…·ï¼Œæ— å®é™…ç”¨é€”
        "teste",  # æ‹¼å†™é”™è¯¯ï¼Œæµ‹è¯•å·¥å…·
        "Carbon management",  # ä¸AI/MLæ— å…³ï¼Œç¯ä¿ç®¡ç†
        # "Web Scraping API",  # çˆ¬è™«å·¥å…·ï¼Œä¸å±äºAI/ML
        "Midjourney best experience",  # é‡å¤ï¼Œä¿ç•™â€œMidJourneyâ€
        # "Explor-Arc's Colors API"  # åç§°ä¸æ˜ï¼ŒéAIæ ¸å¿ƒå·¥å…·
    ]
    tools_to_remove_lower = set(t.lower() for t in ai_ml_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)


    target_category = "Communication"
    # åˆ é™¤17ä¸ªå·¥å…·
    communication_tools_to_remove = [
        "getBs",  # åå­—å«ç³Šï¼Œæ— ç”¨
        "whin",  # æ‹¼å†™ä¸æ˜ï¼Œæ— æ„ä¹‰
        "Dudu",  # æ— æ˜ç¡®ç”¨é€”
        "Punto 61",  # ä¸æ˜å·¥å…·åç§°
        "Barbaraaa",  # æ— æ„ä¹‰åç§°
        "Revista Verde",  # éé€šä¿¡å·¥å…·
        "HoG",  # æ‹¼å†™æ— æ„ä¹‰
        "bcolimited",  # æ— ç”¨åç§°
        "bitikas1",  # æ— æ„ä¹‰åç§°
        # "mobile-recharge-plans-api-tariff-Plans-free",  # ä¸å±äºé€šä¿¡API
        "test apideno",  # æ˜æ˜¾æµ‹è¯•
        "SawyerTest",  # æµ‹è¯•å·¥å…·
        "Another Rapid Test",  # æµ‹è¯•å·¥å…·
        "https://i.imgur.com/JM9TESV.jpg/",  # é“¾æ¥ï¼Œä¸æ˜¯API
        "Weather_dataSet",  # å¤©æ°”æ•°æ®ï¼Œéé€šä¿¡
        "ISS Location",  # ç©ºé—´ç«™ä½ç½®ï¼Œéé€šä¿¡
        # "Flask"  # Webæ¡†æ¶ï¼Œéé€šä¿¡API
    ]
    tools_to_remove_lower = set(t.lower() for t in communication_tools_to_remove)
    clean_category_tools(TO_CLEAN_FILE, target_category, tools_to_remove_lower)

    # å…±æ•´ç†37ä¸ªç±»åˆ«
    # âœ… å·²ä»ç±»åˆ« 'Data' ä¸­åˆ é™¤ 118 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Movies' ä¸­åˆ é™¤ 9 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Video_Images' ä¸­åˆ é™¤ 15 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Financial' ä¸­åˆ é™¤ 12 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Media' ä¸­åˆ é™¤ 10 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'eCommerce' ä¸­åˆ é™¤ 17 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Sports' ä¸­åˆ é™¤ 19 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Email' ä¸­åˆ é™¤ 16 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Mapping' ä¸­åˆ é™¤ 7 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Finance' ä¸­åˆ é™¤ 34 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Health_and_Fitness' ä¸­åˆ é™¤ 4 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Travel' ä¸­åˆ é™¤ 16 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Database' ä¸­åˆ é™¤ 47 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Education' ä¸­åˆ é™¤ 28 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Science' ä¸­åˆ é™¤ 7 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Monitoring' ä¸­åˆ é™¤ 7 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Translation' ä¸­åˆ é™¤ 8 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Tools' ä¸­åˆ é™¤ 38 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Text_Analysis' ä¸­åˆ é™¤ 20 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Advertising' ä¸­åˆ é™¤ 35 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Weather' ä¸­åˆ é™¤ 16 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'News_Media' ä¸­åˆ é™¤ 13 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Business_Software' ä¸­åˆ é™¤ 18 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Gaming' ä¸­åˆ é™¤ 18 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Location' ä¸­åˆ é™¤ 22 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Social' ä¸­åˆ é™¤ 24 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Search' ä¸­åˆ é™¤ 19 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Visual_Recognition' ä¸­åˆ é™¤ 6 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Transportation' ä¸­åˆ é™¤ 5 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Other' ä¸­åˆ é™¤ 45 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Food' ä¸­åˆ é™¤ 20 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Entertainment' ä¸­åˆ é™¤ 34 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Commerce' ä¸­åˆ é™¤ 25 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Music' ä¸­åˆ é™¤ 25 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Business' ä¸­åˆ é™¤ 71 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Artificial_Intelligence_Machine_Learning' ä¸­åˆ é™¤ 4 ä¸ªå·¥å…·ã€‚
    # âœ… å·²ä»ç±»åˆ« 'Communication' ä¸­åˆ é™¤ 15 ä¸ªå·¥å…·ã€‚

def filter_valid_entries():
    """
    å°†åŸè®°å½•ä¸­category_nameã€tool_name å’Œ api_name ä¸åœ¨tool_dataä¸­å‡ºç°çš„è®°å½•ä»data_pathä¸­åˆ é™¤
    è¿‡æ»¤ data_path ä¸­çš„è®°å½•ï¼Œä»…ä¿ç•™é‚£äº›åœ¨ api_dict_path æ‰€æŒ‡å®šç»“æ„ä¸­
    å…¶ category_nameã€tool_name å’Œ api_name éƒ½èƒ½åŒ¹é…çš„è®°å½•ã€‚

    å‚æ•°ï¼š
    - data_path: åŸå§‹æ•°æ®é›† JSON æ–‡ä»¶è·¯å¾„
    - api_dict_path: å·¥å…·ç±»åˆ«-å·¥å…·å-API ååˆ—è¡¨çš„ JSON æ–‡ä»¶è·¯å¾„
    - output_path: ç­›é€‰åçš„è¾“å‡º JSON æ–‡ä»¶è·¯å¾„
    """
    # 1. åŠ è½½æ•°æ®
    with open("/root/autodl-tmp/ToolCombine/ToolsTree0307/query_dataset/G3_query.json", 'r', encoding='utf-8') as f:
        dataset = json.load(f)

    with open("tool_data.json", 'r', encoding='utf-8') as f:
        tool_api_dict = json.load(f)

    # 2. å®šä¹‰æ£€æŸ¥å‡½æ•°
    def is_valid_api_entry(entry):
        for api in entry.get('relevant APIs', []):
            category = api.get('category_name')
            tool = api.get('tool_name')
            api_name = api.get('api_name')
            
            if not (category and tool and api_name):
                return False
            if category not in tool_api_dict:
                return False
            if tool not in tool_api_dict[category]:
                return False
            if 'api_list_names' not in tool_api_dict[category][tool]:
                return False
            if api_name not in tool_api_dict[category][tool]['api_list_names']:
                return False
        return True

    # 3. è¿‡æ»¤æ•°æ®
    cleaned_dataset = [entry for entry in dataset if is_valid_api_entry(entry)]

    # 4. å†™å…¥ç»“æœ
    with open("/root/autodl-tmp/ToolCombine/ToolsTree0307/query_dataset/G3_query.json", 'w', encoding='utf-8') as f:
        json.dump(cleaned_dataset, f, ensure_ascii=False, indent=2)

    print(f"ç­›é€‰åä¿ç•™ {len(cleaned_dataset)} æ¡è®°å½•ï¼Œå·²ä¿å­˜è‡³G3_query.json")

def merge_and_deduplicate(key='query_id'):
    """
    å°†ä¸¤ä¸ªjsonæ–‡ä»¶åˆå¹¶æˆä¸€ä¸ªjsonæ–‡ä»¶ï¼Œå³å°†ä¸¤ä¸ªæŸ¥è¯¢é›†åˆå¹¶æˆä¸€ä¸ªå¹¶å»é‡
    """
    # è¯»å–æ–‡ä»¶
    with open("/root/autodl-tmp/AnyTool/data/test_instruction/G2_category.json", 'r', encoding='utf-8') as f1:
        list1 = json.load(f1)
    with open("/root/autodl-tmp/AnyTool/data/test_instruction/G2_instruction.json", 'r', encoding='utf-8') as f2:
        list2 = json.load(f2)
    
    # ç”¨å­—å…¸å»é‡ï¼ˆåå‡ºç°çš„å¯¹è±¡è¦†ç›–å…ˆå‡ºç°çš„ï¼‰
    unique_dict = {}
    for item in list1 + list2:
        unique_dict[item[key]] = item  # ç›¸åŒIDçš„å¯¹è±¡ä¼šè¢«è¦†ç›–
    
    # è½¬æ¢ä¸ºåˆ—è¡¨
    merged = list(unique_dict.values())
    
    # ä¿å­˜ç»“æœ
    with open("G2_query.json", 'w', encoding='utf-8') as f:
        json.dump(merged, f, ensure_ascii=False, indent=2)
    
    print(f"å»é‡åæ€»å…ƒç´ æ•°ï¼š{len(merged)}ï¼Œé‡å¤IDå·²å¤„ç†")

def replace_relevant_apis(json_path):
    """
    æ„å»ºä¸€ä¸ªå¿«é€ŸæŸ¥æ‰¾å­—å…¸ï¼Œä»¥ (tool_name, api_name) ä¸ºé”®ï¼Œæ˜ å°„åˆ° API çš„åŸºæœ¬å…ƒä¿¡æ¯ã€‚

    å‚æ•°:
        api_list (list of dict): åŒ…å«å¤šä¸ª API å®šä¹‰çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºä¸€ä¸ªå­—å…¸ï¼Œè‡³å°‘åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
            - "category_name": æ‰€å±ç±»åˆ«
            - "tool_name": å·¥å…·åç§°
            - "api_name": æ¥å£åç§°

    è¿”å›:
        dict: ä¸€ä¸ªå­—å…¸ï¼Œé”®ä¸º (tool_name, api_name) çš„å…ƒç»„ï¼Œå€¼ä¸ºå¯¹åº” API çš„ç®€åŒ–ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«ï¼š
            - "category_name"
            - "tool_name"
            - "api_name"
    """
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    for entry in data:
        api_list = entry.get("api_list", [])
        relevant_apis = entry.get("relevant APIs", [])

        # æ„å»ºæŸ¥æ‰¾è¡¨ {(tool_name, api_name): å¯¹åº”ç®€åŒ–å­—æ®µ}
        api_lookup = {
            (api["tool_name"], api["api_name"]): {
                "category_name": api["category_name"],
                "tool_name": api["tool_name"],
                "api_name": api["api_name"]
            }
            for api in api_list
        }

        # æ›¿æ¢ relevant APIs
        new_relevant_apis = []
        for tool_name, api_name in relevant_apis:
            key = (tool_name, api_name)
            if key in api_lookup:
                new_relevant_apis.append(api_lookup[key])
            else:
                print(f"âš  æœªæ‰¾åˆ°åŒ¹é…é¡¹: {key}")

        entry["relevant APIs"] = new_relevant_apis

    # ä¿å­˜ä¿®æ”¹åçš„ç»“æœ
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    print("âœ… relevant APIs å­—æ®µå·²æˆåŠŸæ›¿æ¢ã€‚")

def filter_unsolvable_queries(json_path):
    """
    ä½¿ç”¨ gpt() æ¥å£åˆ¤æ–­æ¯æ¡ query æ˜¯å¦æ»¡è¶³å·¥å…·ç»„åˆè§£å†³æ¡ä»¶ï¼Œ
    ç­›é™¤ä¸æ»¡è¶³æ¡ä»¶çš„é¡¹ï¼Œå¹¶å°†ç»“æœè¦†ç›–å†™å›åŸå§‹ JSON æ–‡ä»¶ã€‚

    ç­›é€‰è§„åˆ™åŸºäº ToolBench å¯è§£æ€§æ ‡å‡†ï¼š
    1. ç¼ºå°‘å…³é”®ä¿¡æ¯ï¼ˆå¦‚ç”µè¯å·ç ã€çœŸå® IDï¼‰ï¼›
    2. å«æœ‰ä¼ªé€ å‚æ•°ï¼ˆå¦‚ä¸å­˜åœ¨çš„ URLï¼‰ï¼›
    3. æ˜ç¡®æŒ‡å®šäº†æŸä¸ª APIï¼›
    4. æŸ¥è¯¢ä¸åˆç†ï¼ˆå¦‚è¯·æ±‚å¤ªå¹¿æ³›ã€æ¨¡ç³Šï¼‰ï¼›
    """
    # è¯»å–åŸå§‹æ•°æ®
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    filtered = []
    dropped = 0

    for item in tqdm(data, desc="Filtering queries"):
        query = item.get("query", "").strip()
        if not query:
            dropped += 1
            continue
        prompt = FILTER_DATASET_PROMPT.replace("{query}", query)
        try:
            result = gpt_for_data(prompt).choices[0].message.content
            print(result)  # æ¥å£å‡½æ•°ï¼Œè¿”å› "Yes" æˆ– "No"
            if isinstance(result, str) and result.strip().lower().startswith("yes"):
                filtered.append(item)
            else:
                dropped += 1
        except Exception as e:
            print(f"âš  Error filtering query: {e}")
            dropped += 1
        # time.sleep(0.5)  # é™é€Ÿï¼Œé¿å… API é™æµ

    # å†™å›æ¸…æ´—åçš„æ•°æ®
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(filtered, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… ç­›é€‰å®Œæˆï¼šå…±å¤„ç† {len(data)} æ¡ï¼Œä¿ç•™ {len(filtered)} æ¡ï¼Œå‰”é™¤ {dropped} æ¡ã€‚")

def merge_json_files():
    """
    å°†å¤šä¸ª JSON æ–‡ä»¶ï¼ˆæ¯ä¸ªæ˜¯ä¸€ä¸ª listï¼‰åˆå¹¶æˆä¸€ä¸ªå¤§ listï¼Œå¹¶ä¿å­˜åˆ°è¾“å‡ºæ–‡ä»¶ä¸­ã€‚

    å‚æ•°:
        input_files (list[str]): è¾“å…¥æ–‡ä»¶è·¯å¾„åˆ—è¡¨ã€‚
        output_file (str): åˆå¹¶åä¿å­˜çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„ã€‚
    """
    input_files = [
        '/root/autodl-tmp/ToolCombine/ToolsTree0307/query_dataset/G1_query.json',
        '/root/autodl-tmp/ToolCombine/ToolsTree0307/query_dataset/G2_query.json',
        '/root/autodl-tmp/ToolCombine/ToolsTree0307/query_dataset/G3_query.json']
    output_file = '/root/autodl-tmp/ToolCombine/ToolsTree0307/query_dataset/toolbench.json'
    merged_data = []

    for file_path in input_files:
        if not os.path.exists(file_path):
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {file_path}")
            continue
        with open(file_path, "r", encoding="utf-8") as f:
            try:
                data = json.load(f)
                if isinstance(data, list):
                    merged_data.extend(data)
                else:
                    print(f"âš ï¸ æ–‡ä»¶ä¸æ˜¯ JSON åˆ—è¡¨ï¼Œè·³è¿‡: {file_path}")
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON è§£æå¤±è´¥ï¼Œè·³è¿‡: {file_path}ï¼Œé”™è¯¯: {e}")
    
    # ä¿å­˜åˆå¹¶ç»“æœ
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    with open(output_file, "w", encoding="utf-8") as out_f:
        json.dump(merged_data, out_f, indent=2, ensure_ascii=False)

    print(f"âœ… åˆå¹¶å®Œæˆï¼Œæ€»è®¡æ¡ç›®æ•°: {len(merged_data)}ï¼Œä¿å­˜è‡³: {output_file}")

def extract_api_names():
    """
    è¯»å–åŸå§‹å·¥å…· JSON æ–‡ä»¶ï¼Œæå–æ¯ä¸ªå·¥å…·çš„ API è·¯å¾„ï¼Œé‡æ„ä¸ºæ–°çš„ç»“æ„å¹¶ä¿å­˜ã€‚
    """
    input_file_path = "/root/autodl-tmp/ToolCombine/ToolsTree0307/data/api_details.json"
    with open(input_file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    output_data = {}

    for category, tools in data.items():
        output_data[category] = {}
        for tool_name, tool_info in tools.items():
            api_list = tool_info.get("api_list", [])
            # æå– name å­—æ®µ
            api_names = [api.get("name") for api in api_list if isinstance(api, dict) and "name" in api]
            output_data[category][tool_name] = {
                "api_list_names": api_names
            }

    output_file_path = "tool_data.json"
    with open(output_file_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)

    print(f"âœ… æå–å®Œæˆï¼Œç»“æœä¿å­˜è‡³: {output_file_path}")


if __name__ == '__main__':
    # ç¬¬ä¸€æ­¥ï¼Œåˆ é™¤ä¸€äº›ä¸å¸¸è§çš„ç±»åˆ«
    # remove_specified_keys('tool_data_new_v2.json', None, 'tool_data_new_v2.json')
    # get_all_tools_list()
    # merge_info()
    # get_all_tools_list_no()
    # ç¬¬äºŒæ­¥ï¼Œåˆ é™¤æ²¡æœ‰å·¥å…·æè¿°çš„tool
    # clean_null_tool()
    # remove_deleted_tools_from_second_file()
    # ç¬¬ä¸‰æ­¥ï¼Œåˆ é™¤æ²¡æœ‰æè¿°çš„api
    # remove_api()
    # clean_null_api()
    # count_apis_per_tool_from_file("./data/tool_data.json")

    # ç¬¬å››æ­¥ï¼Œæ‰‹åŠ¨åˆ é™¤ä¸èƒ½è§åçŸ¥æ„çš„å·¥å…·ï¼Œæµ‹è¯•å·¥å…·ç­‰ç­‰

    # ç¬¬äº”æ­¥ï¼Œå°†ä¿¡æ¯æ¯”è¾ƒå…¨çš„å»é™¤æ²¡æœ‰çš„apiä¿¡æ¯
    # filter_api_by_reference()

    # ç¬¬å…­æ­¥ï¼Œå°†å·¥å…·å’Œapiåå‰åçš„ç©ºæ ¼å»é™¤
    # clean_and_overwrite_tool_file()
    # clean_api_list_names()
    # count_json_elements("/root/autodl-tmp/AnyTool/atb_data/anytoolbench_old.json")
    # count_json_elements("/root/autodl-tmp/ToolCombine/ToolsTree0307/query_dataset/anytoolbench.json")
    # count_json_elements("/root/autodl-tmp/ToolCombine/ToolsTree0307/query_dataset/toolbench.json")
    # count_json_elements("/root/autodl-tmp/ToolCombine/ToolsTree0307/query_dataset/G1_query.json")
    # count_json_elements("/root/autodl-tmp/ToolCombine/ToolsTree0307/query_dataset/G2_query.json")
    # count_json_elements("/root/autodl-tmp/ToolCombine/ToolsTree0307/query_dataset/G3_query.json")
    # get_all_tools_list_no()

    # ç»Ÿè®¡apiæ•°é‡
    count_api_number()
    # filter_valid_entries()
    # merge_and_deduplicate()
    # replace_relevant_apis("/root/autodl-tmp/ToolCombine/ToolsTree0307/query_dataset/G3_query.json")
    # filter_valid_entries()
    # filter_unsolvable_queries("/root/autodl-tmp/ToolCombine/ToolsTree0307/query_dataset/G2_query.json")
    
    # merge_json_files()
    # extract_api_names()




